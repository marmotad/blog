<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">


<link rel="stylesheet" href="/blog/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"marmotad.github.io","root":"/blog/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="标签与标签选择器它是附加在Kubernetes任何资源对象之上的键值型数据，常用于标签选择器的匹配度检查，从而完成资源筛选。Kubernetes系统的部分基础功能的实现也要依赖标签和标签选择器，例如Service筛选并关联后端Pod对象，由ReplicaSet、StatefulSet和DaemonSet等控制器过滤并关联后端Pod对象等，从而提升用户的资源管理效率。 资源标签标签可在资源创建时直接">
<meta property="og:type" content="article">
<meta property="og:title" content="Service和服务发现">
<meta property="og:url" content="https://marmotad.github.io/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/index.html">
<meta property="og:site_name" content="marmotad">
<meta property="og:description" content="标签与标签选择器它是附加在Kubernetes任何资源对象之上的键值型数据，常用于标签选择器的匹配度检查，从而完成资源筛选。Kubernetes系统的部分基础功能的实现也要依赖标签和标签选择器，例如Service筛选并关联后端Pod对象，由ReplicaSet、StatefulSet和DaemonSet等控制器过滤并关联后端Pod对象等，从而提升用户的资源管理效率。 资源标签标签可在资源创建时直接">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://marmotad.github.io/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131215422.png">
<meta property="og:image" content="https://marmotad.github.io/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131237759.png">
<meta property="og:image" content="https://marmotad.github.io/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131341607.png">
<meta property="og:image" content="https://marmotad.github.io/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131409842.png">
<meta property="og:image" content="https://marmotad.github.io/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131440521.png">
<meta property="og:image" content="https://marmotad.github.io/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131506181.png">
<meta property="og:image" content="https://marmotad.github.io/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131528411.png">
<meta property="og:image" content="https://marmotad.github.io/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131606248.png">
<meta property="og:image" content="https://marmotad.github.io/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123132640583.png">
<meta property="og:image" content="https://marmotad.github.io/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123133725398.png">
<meta property="og:image" content="https://marmotad.github.io/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123134247463.png">
<meta property="og:image" content="https://marmotad.github.io/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123134329215.png">
<meta property="og:image" content="https://marmotad.github.io/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123134355773.png">
<meta property="article:published_time" content="2022-02-09T11:48:21.000Z">
<meta property="article:modified_time" content="2022-02-09T11:49:31.197Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="Kubernetes">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://marmotad.github.io/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131215422.png">

<link rel="canonical" href="https://marmotad.github.io/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Service和服务发现 | marmotad</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/blog/atom.xml" title="marmotad" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">marmotad</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://marmotad.github.io/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="myBlog">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="marmotad">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Service和服务发现
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2022-02-09 19:48:21 / 修改时间：19:49:31" itemprop="dateCreated datePublished" datetime="2022-02-09T19:48:21+08:00">2022-02-09</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="标签与标签选择器"><a href="#标签与标签选择器" class="headerlink" title="标签与标签选择器"></a>标签与标签选择器</h1><p>它是附加在Kubernetes任何资源对象之上的键值型数据，常用于标签选择器的匹配度检查，从而完成资源筛选。Kubernetes系统的部分基础功能的实现也要依赖标签和标签选择器，例如Service筛选并关联后端Pod对象，由ReplicaSet、StatefulSet和DaemonSet等控制器过滤并关联后端Pod对象等，从而提升用户的资源管理效率。</p>
<h2 id="资源标签"><a href="#资源标签" class="headerlink" title="资源标签"></a>资源标签</h2><p>标签可在资源创建时直接指定，也可随时按需添加在活动对象上。一个对象可拥有不止一个标签，而同一个标签也可添加至多个对象之上。下面是较为常用的标签。</p>
<ul>
<li>版本标签：”release” : “stable”，”release” : “canary”，”release” : “beta”。</li>
<li>环境标签：”environment” : “dev”，”environment” : “qa”，”environment” : “prod”。</li>
<li>应用标签：”app” : “ui”，”app” : “as”，”app” : “pc”，”app” : “sc”。</li>
<li>架构层级标签：”tier” : “frontend”，”tier” : “backend”，”tier” : “cache”。</li>
<li>分区标签：”partition” : “customerA”，”partition” : “customerB”。</li>
<li>品控级别标签：”track” : “daily”，”track” : “weekly”。</li>
</ul>
<p>标签中的<font color="red">键名称通常由“键前缀”和“键名”组成，其格式形如KEY_PREFIX/KEY_NAME，键前缀为可选部分。键名至多能使用63个字符，支持字母、数字、连接号（-）、下划线（）、点号（.）等字符，且只能以字母或数字开头。而键前缀必须为DNS子域名格式，且不能超过253个字符。省略键前缀时，键将被视为用户的私有数据。由Kubernetes系统组件或第三方组件自动为用户资源添加的键必须使用键前缀，kubernetes.io/和k8s.io/前缀预留给了Kubernetes的核心组件使用，例如Node对象上常用的kubernetes.io/os、kubernetes.io/arch和kubernetes.io/hostname等。<br><font color="red">标签的键值必须不能多于63个字符，键值要么为空，要么以字母或数字开头及结尾，且中间只能使用字母、数字、连接号（-）、下划线（）或点号（.）等字符。</font></font></p>
<h3 id="创建资源时定义标签"><a href="#创建资源时定义标签" class="headerlink" title="创建资源时定义标签"></a>创建资源时定义标签</h3><p>创建资源时，可直接在其metadata中嵌套使用labels字段定义要附加的标签项。例如在下面的Namespace资源配置清单文件中，示例ns-with-labels.yaml中使用了两个标签，env=dev和app=eshop。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">eshop</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">eshop</span></span><br><span class="line">    <span class="attr">env:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">finalizers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">kubernetes</span></span><br></pre></td></tr></table></figure>

<ul>
<li>可在kubectl get namespaces命令中使用–show-labels选项，以额外显示对象的标签信息。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl apply -f ns-with-labels.yaml</span> </span><br><span class="line">namespace/eshop created</span><br><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl get namespaces eshop --show-labels</span></span><br><span class="line">NAME  STATUS   AGE   LABELS</span><br><span class="line">demoapp   Active      11s   app=eshop,env=dev</span><br></pre></td></tr></table></figure>

<ul>
<li>kubectl get命令上使用-L key1,key2,…选项可指定有特定键的标签信息。例如，仅显示eshop名称空间上的env和app标签：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl get namespaces eshop -L <span class="built_in">env</span>,app</span></span><br><span class="line">NAME    STATUS   AGE   ENV   APP</span><br><span class="line">eshop       Active     89s    dev   eshop</span><br></pre></td></tr></table></figure>

<ul>
<li>kubectl label命令可直接管理活动对象的标签，以按需进行添加或修改等操作。例如为eshop名称空间添加release=beta标签：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl label namespaces/eshop release=beta</span></span><br><span class="line">namespace/eshop labeled</span><br></pre></td></tr></table></figure>

<ul>
<li>已经附带了指定键名的标签，使用kubectl label为其设定新的键值时需同时使用–overwrite命令，强制覆盖原有键值。例如，将eshop名称空间的release标签值修改为canary：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl label namespaces/eshop release=canary --overwrite</span></span><br><span class="line">namespace/eshop labeled</span><br></pre></td></tr></table></figure>

<ul>
<li>删除活动对象上的标签时同样要使用kubectl label命令，但仅需要指定标签名称并紧跟一个减号“–”，例如，下面的命令首先删除eshop名称空间中的env标签，而后显示其现有的所有标签：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl label namespaces/eshop <span class="built_in">env</span>-</span></span><br><span class="line">namespace/eshop labeled</span><br><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl get namespaces eshop --show-labels</span> </span><br><span class="line">NAME    STATUS   AGE     LABELS</span><br><span class="line">eshop   Active   6m46s   app=eshop,release=beta</span><br></pre></td></tr></table></figure>

<h2 id="标签选择器"><a href="#标签选择器" class="headerlink" title="标签选择器"></a>标签选择器</h2><p>标签选择器用于表达标签的查询条件或选择标准，目前Kubernetes API支持两个选择器：基于等值关系（equality-based）的标签选项器与基于集合关系（set-based）的标签选择器。在指定多个选择器时需要以逗号分隔，<font color="red">各选择器之间遵循逻辑“与”，即必须要满足所有条件，而且空值的选择器将不选择任何对象。</font></p>
<ul>
<li>基于等值关系的标签选择器</li>
</ul>
<p>可用操作符有=、==和!=，其中前两个意义相同，都表示“等值”关系，最后一个表示“不等”。例如env=dev和env!=prod都是基于等值关系的选择器。</p>
<ul>
<li>基于集合的标签选择器</li>
</ul>
<p>根据标签名的一组值进行筛选，它支持in、notin和exists这3种操作符，例如tier in (frontend,backend)表示所有包含tier标签且其值为frontend或backend的资源对象。</p>
<ul>
<li>kubectl get命令的“-l”选项能够指定使用标签选择器筛选目标资源，例如，如下命令显示标签release的值不等于beta，且标签app的值等于eshop的所有名称空间：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl get namespaces -l <span class="string">&#x27;release!=beta,app=eshop&#x27;</span>  -L app,release</span></span><br><span class="line">NAME      STATUS      AGE   APP     RELEASE</span><br><span class="line">eshop     Active      60m   eshop   canary</span><br></pre></td></tr></table></figure>

<ul>
<li>基于集合关系的标签选择器用于基于一组值进行过滤，它支持in、notin和exists 3种操作符，各操作符的使用格式及意义如下。<ul>
<li>KEY in (VALUE1,VALUE2,…)：指定键名的值存在于给定的列表中即满足条件。</li>
<li>KEY notin (VALUE1,VALUE2,…)：指定键名的值不存在于给定列表中即满足条件。</li>
<li>KEY：所有存在此键名标签的资源。</li>
<li>!KEY：所有不存在此键名标签的资源。</li>
<li>例如，下面的命令可以过滤出标签键名release的值为beta或canary的所有Namespace对象：</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl get namespaces -l &#x27;release in (beta,canary)&#x27; -L release</span><br><span class="line">NAME       STATUS     AGE   RELEASE</span><br><span class="line">eshop      Active     63m   canary</span><br></pre></td></tr></table></figure>

<ul>
<li>再如，下面的命令可以列出集群中拥有node-role.kubernetes.io标签的各Node对象：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl get nodes -l <span class="string">&#x27;node-role.kubernetes.io/master&#x27;</span> -L kubernetes.io/hostname</span></span><br><span class="line">NAME                     STATUS   ROLES    AGE   VERSION   HOSTNAME</span><br><span class="line">k8s-master01.ilinux.io   Ready    master   25d   v1.17.3   k8s-master01.ilinux.io</span><br><span class="line">k8s-master02.ilinux.io   Ready    master   25d   v1.17.3   k8s-master02.ilinux.io</span><br><span class="line">k8s-master03.ilinux.io   Ready    master   25d   v1.17.3   k8s-master03.ilinux.io</span><br></pre></td></tr></table></figure>


<p>此外，Kubernetes的诸多资源对象必须以标签选择器的方式关联到Pod资源对象，例如Service资源在spec字段中嵌套使用selector字段定义标签选择器，而Deployment与StatefulSet等资源在selector字段中通过matchLabels和matchExpressions构造复杂的标签选择机制。</p>
<ul>
<li>matchLabels：直接给定键值对指定标签选择器。</li>
<li>matchExpressions：基于表达式指定的标签选择器列表，每个选择器形如{key: KEY_NAME, operator: OPERATOR, values: [VALUE1,VALUE2,…]}，选择器列表间为“逻辑与”关系；使用In或NotIn操作符时，其values必须为非空的字符串列表，而使用Exists或DostNotExist时，其values必须为空。</li>
<li>下面的资源清单片段是一个示例，它同时定义了两类标签选择器。</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">selector:</span></span><br><span class="line">  <span class="attr">matchLabels:</span></span><br><span class="line">    <span class="attr">component:</span> <span class="string">redis</span></span><br><span class="line">  <span class="attr">matchExpressions:</span></span><br><span class="line">    <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">tier</span>, <span class="attr">operator:</span> <span class="string">In</span>, <span class="attr">values:</span> [<span class="string">cache</span>]&#125;</span><br><span class="line">    <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">environment</span>, <span class="attr">operator:</span> <span class="string">Exists</span>, <span class="string">values:</span>&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Service与服务发现"><a href="#Service与服务发现" class="headerlink" title="Service与服务发现"></a>Service与服务发现</h1><p>Service对象的IP地址都仅在Kubernetes集群内可达，它们无法接入集群外部的访问流量。在解决此类问题时，除了可以在单一节点上做端口（hostPort）暴露及让Pod资源共享使用工作节点的网络名称空间（hostNetwork）之外，更推荐用户使用NodePort或LoadBalancer类型的Service资源，或者是有七层负载均衡能力的Ingress资源。</p>
<h2 id="Service资源及其实现模型"><a href="#Service资源及其实现模型" class="headerlink" title="Service资源及其实现模型"></a>Service资源及其实现模型</h2><p>Service是Kubernetes的核心资源类型之一。它事实上是一种抽象：通过规则定义出由多个Pod对象组合而成的逻辑集合，以及访问这组Pod的策略。Service关联Pod资源的规则要借助标签选择器完成。</p>
<h3 id="Service资源概述"><a href="#Service资源概述" class="headerlink" title="Service资源概述"></a>Service资源概述</h3><p>Service资源基于标签选择器把筛选出的一组Pod对象定义成一个逻辑组合，并通过自己的IP地址和端口将请求分发给该组内的Pod对象。</p>
<p><img src="/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131215422.png" alt="image-20220123131215422"></p>
<p>Service对象的IP地址（可称为ClusterIP或ServiceIP）是虚拟IP地址，由Kubernetes系统在Service对象创建时在专用网络（Service Network）地址中自动分配或由用户手动指定，并且在Service对象的生命周期中保持不变。Service基于端口过滤到达其IP地址的客户端请求，并根据定义将请求转发至其后端的Pod对象的相应端口之上，因此这种代理机制也称为“端口代理”或四层代理，工作于TCP/IP协议栈的传输层。<br>Service对象会通过API Server持续监视（watch）标签选择器匹配到的后端Pod对象，并实时跟踪这些Pod对象的变动情况，例如IP地址变动以及Pod对象的增加或删除等。不过，Service并不直接连接至Pod对象，它们之间还有一个中间层——Endpoints资源对象，该资源对象是一个由IP地址和端口组成的列表，这些IP地址和端口则来自由Service的标签选择器匹配到的Pod对象。这也是很多场景中会使用“Service的后端端点”这一术语的原因。默认情况下，创建Service资源对象时，其关联的Endpoints对象会被自动创建。</p>
<h3 id="kube-proxy代理模型"><a href="#kube-proxy代理模型" class="headerlink" title="kube-proxy代理模型"></a>kube-proxy代理模型</h3><p>每个工作节点的kube-proxy组件通过API Server持续监控着各Service及其关联的Pod对象，并将Service对象的创建或变动实时反映至当前工作节点上相应的iptables或ipvs规则上。客户端、Service及Pod对象的关系如图7-3所示。</p>
<p><img src="/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131237759.png" alt="image-20220123131237759"></p>
<p>Service对象的ClusterIP事实上是用于生成iptables或ipvs规则时使用的IP地址，它仅用于实现Kubernetes集群网络内部通信，且仅能够以规则中定义的转发服务的请求作为目标地址予以响应，这也是它之所以被称作虚拟IP的原因之一。kube-proxy把请求代理至相应端点的方式有3种：userspace、iptables和ipvs。</p>
<h4 id="userspace代理模型"><a href="#userspace代理模型" class="headerlink" title="userspace代理模型"></a>userspace代理模型</h4><p>此处的userspace是指Linux操作系统的用户空间。在这种模型中，kube-proxy负责跟踪API Server上Service和Endpoints对象的变动（创建或移除），并据此调整Service资源的定义。对于每个Service对象，它会随机打开一个本地端口（运行于用户空间的kube-proxy进程负责监听），任何到达此代理端口的连接请求都将被代理至当前Service资源后端的各Pod对象，至于哪个Pod对象会被选中则取决于当前Service资源的调度方式，默认调度算法是轮询（round-robin）。userspace代理模型工作逻辑如图7-4所示。另外，此类Service对象还会创建iptables规则以捕获任何到达ClusterIP和端口的流量。在Kubernetes 1.1版本之前，userspace是默认的代理模型。</p>
<p><img src="/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131341607.png" alt="image-20220123131341607"></p>
<p>在这种代理模型中，请求流量到达内核空间后经由套接字送往用户空间中的kube-proxy进程，而后由该进程送回内核空间，发往调度分配的目标后端Pod对象。因请求报文在内核空间和用户空间来回转发，所以必然导致模型效率不高。</p>
<h4 id="iptables代理模型"><a href="#iptables代理模型" class="headerlink" title="iptables代理模型"></a>iptables代理模型</h4><p>创建Service对象的操作会触发集群中的每个kube-proxy并将其转换为定义在所属节点上的iptables规则，用于转发工作接口接收到的、与此Service资源ClusterIP和端口相关的流量。客户端发来请求将直接由相关的iptables规则进行目标地址转换（DNAT）后根据算法调度并转发至集群内的Pod对象之上，而无须再经由kube-proxy进程进行处理，因而称为iptables代理模型，如图7-5所示。对于每个Endpoints对象，Service资源会为其创建iptables规则并指向其iptables地址和端口，而流量转发到多个Endpoint对象之上的默认调度机制是随机算法。iptables代理模型由Kubernetes v1.1版本引入，并于v1.2版本成为默认的类型。</p>
<p><img src="/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131409842.png" alt="image-20220123131409842"></p>
<p>在iptables代理模型中，Service的服务发现和负载均衡功能都使用iptables规则实现，而无须将流量在用户空间和内核空间来回切换，因此更为高效和可靠，但是性能一般，而且受规模影响较大，仅适用于少量Service规模的集群。</p>
<h4 id="ipvs代理模型"><a href="#ipvs代理模型" class="headerlink" title="ipvs代理模型"></a>ipvs代理模型</h4><p>Kubernetes自v1.9版本起引入ipvs代理模型，且自v1.11版本起成为默认设置。在此种模型中，kube-proxy跟踪API Server上Service和Endpoints对象的变动，并据此来调用netlink接口创建或变更ipvs（NAT）规则，如图7-6所示。它与iptables规则的不同之处仅在于客户端请求流量的调度功能由ipvs实现，余下的其他功能仍由iptables完成。</p>
<p><img src="/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131440521.png" alt="image-20220123131440521"></p>
<p>ipvs代理模型中Service的服务发现和负载均衡功能均基于内核中的ipvs规则实现。类似于iptables，ipvs也构建于内核中的netfilter之上，但它使用hash表作为底层数据结构且工作于内核空间，因此具有流量转发速度快、规则同步性能好的特性，适用于存在大量Service资源且对性能要求较高的场景。ipvs代理模型支持rr、lc、dh、sh、sed和nq等多种调度算法。</p>
<h3 id="Service资源类型"><a href="#Service资源类型" class="headerlink" title="Service资源类型"></a>Service资源类型</h3><p>无论哪一种代理模型，Service资源都可统一根据其工作逻辑分为ClusterIP、NodePort、LoadBalancer和ExternalName这4种类型。</p>
<h4 id="（1）ClusterIP"><a href="#（1）ClusterIP" class="headerlink" title="（1）ClusterIP"></a>（1）ClusterIP</h4><p>通过集群内部IP地址暴露服务，ClusterIP地址仅在集群内部可达，因而无法被集群外部的客户端访问。此为默认的Service类型。</p>
<h4 id="（2）NodePort"><a href="#（2）NodePort" class="headerlink" title="（2）NodePort"></a>（2）NodePort</h4><p>NodePort类型是对ClusterIP类型Service资源的扩展，它支持通过特定的节点端口接入集群外部的请求流量，并分发给后端的Server Pod处理和响应。因此，这种类型的Service既可以被集群内部客户端通过ClusterIP直接访问，也可以通过套接字&lt;NodeIP&gt;: &lt;NodePort&gt;与集群外部客户端进行通信，如图7-7所示。显然，若集群外部的请求报文首先到的节点并非Service调度的目标Server Pod所在的节点，<font color="red">该请求必然因需要额外的转发过程（跃点）和更多的处理步骤而产生更多延迟</font></p>
<p><img src="/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131506181.png" alt="image-20220123131506181"></p>
<h4 id="（3）LoadBalancer"><a href="#（3）LoadBalancer" class="headerlink" title="（3）LoadBalancer"></a>（3）LoadBalancer</h4><p>这种类型的Service依赖于部署在IaaS云计算服务之上并且能够调用其API接口创建软件负载均衡器的Kubernetes集群环境。LoadBalancer Service构建在NodePort类型的基础上，通过云服务商提供的软负载均衡器将服务暴露到集群外部，因此它也会具有NodePort和ClusterIP。简言之，创建LoadBalancer类型的Service对象时会在集群上创建一个NodePort类型的Service，并额外触发Kubernetes调用底层的IaaS服务的API创建一个软件负载均衡器，而集群外部的请求流量会先路由至该负载均衡器，并由该负载均衡器调度至各节点上该Service对象的NodePort，如图7-8所示。该Service类型的优势在于，<font color="red">它能够把来自集群外部客户端的请求调度至所有节点（或部分节点）的NodePort之上，而不是让客户端自行决定连接哪个节点，也避免了因客户端指定的节点故障而导致的服务不可用。</font></p>
<p><img src="/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131528411.png" alt="image-20220123131528411"></p>
<h4 id="（4）ExternalName"><a href="#（4）ExternalName" class="headerlink" title="（4）ExternalName"></a>（4）ExternalName</h4><p>通过将Service映射至由externalName字段的内容指定的主机名来暴露服务，此主机名需要被DNS服务解析至CNAME类型的记录中。换言之，此种类型不是定义由Kubernetes集群提供的服务，而是把集群外部的某服务以DNS CNAME记录的方式映射到集群内，从而让集群内的Pod资源能够访问外部服务的一种实现方式，如图7-9所示。因此，这种类型的Service没有ClusterIP和NodePort，没有标签选择器用于选择Pod资源，也不会有Endpoints存在。</p>
<p><img src="/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123131606248.png" alt="image-20220123131606248"></p>
<p>总体来说，若需要将Service资源发布至集群外部，应该将其配置为NodePort或Load-Balancer类型，而若要把外部的服务发布于集群内部供Pod对象使用，则需要定义一个ExternalName类型的Service资源，只是这种类型的实现要依赖于v1.7及更高版本的Kubernetes。</p>
<h2 id="应用Service资源"><a href="#应用Service资源" class="headerlink" title="应用Service资源"></a>应用Service资源</h2><p>Service是Kubernetes核心API群组（core）中的标准资源类型之一，其管理操作的基本逻辑类似于Namespace和ConfigMap等资源，支持基于命令行和配置清单的管理方式。Service资源配置规范中常用的字段及意义如下所示。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">…</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">…</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="string">type</span> <span class="string">&lt;string&gt;</span>                 <span class="comment"># Service类型，默认为ClusterIP</span></span><br><span class="line">  <span class="string">selector</span> <span class="string">&lt;map[string]string&gt;</span>  <span class="comment"># 等值类型的标签选择器，内含“与”逻辑</span></span><br><span class="line">  <span class="string">ports：</span>                       <span class="comment"># Service的端口对象列表</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">name</span> <span class="string">&lt;string&gt;</span>               <span class="comment"># 端口名称</span></span><br><span class="line">    <span class="string">protocol</span> <span class="string">&lt;string&gt;</span>           <span class="comment"># 协议，目前仅支持TCP、UDP和SCTP，默认为TCP</span></span><br><span class="line">    <span class="string">port</span> <span class="string">&lt;integer&gt;</span>              <span class="comment"># Service的端口号，被映射进Pod上的应用程序监听的端口； 而且如果后端Pod有多个端口，并且每个端口都想通过SErvice暴露的话，每个都要单独定义。 最终接收请求的是PodIP和containerPort；</span></span><br><span class="line">    <span class="string">targetPort</span>  <span class="string">&lt;string&gt;</span>        <span class="comment">#  后端目标进程的端口号或名称，名称需由Pod规范定义</span></span><br><span class="line">    <span class="string">nodePort</span> <span class="string">&lt;integer&gt;</span>          <span class="comment"># 节点端口号，仅适用于NodePort和LoadBalancer类型</span></span><br><span class="line">  <span class="string">clusterIP</span>  <span class="string">&lt;string&gt;</span>           <span class="comment"># Service的集群IP，建议由系统自动分配,也支持由用户手动分配</span></span><br><span class="line">  <span class="string">externalTrafficPolicy</span>  <span class="string">&lt;string&gt;</span> <span class="comment"># 外部流量策略处理方式，Local表示由当前节点处理，</span></span><br><span class="line">　　　                            <span class="comment"># Cluster表示向集群范围内调度</span></span><br><span class="line">  <span class="string">loadBalancerIP</span>  <span class="string">&lt;string&gt;</span>        <span class="comment"># 外部负载均衡器使用的IP地址，仅适用于LoadBlancer</span></span><br><span class="line">  <span class="string">externalName</span> <span class="string">&lt;string&gt;</span>           <span class="comment"># 外部服务名称，该名称将作为Service的DNS CNAME值</span></span><br></pre></td></tr></table></figure>

<h3 id="应用ClusterIP-Service资源"><a href="#应用ClusterIP-Service资源" class="headerlink" title="应用ClusterIP Service资源"></a>应用ClusterIP Service资源</h3><p>创建Service对象的常用方法有两种：一是利用此前曾使用过的kubectl create service命令创建，另一个则是利用资源配置清单创建。Service资源对象的期望状态定义在spec字段中，较为常用的内嵌字段为selector和ports，用于定义标签选择器和服务端口。下面的配置清单是定义在services-clusterip-demo.yaml中的一个Service资源示例：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">demoapp-svc</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">demoapp</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>       <span class="comment"># 端口名称标识</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span>    <span class="comment"># 协议，支持TCP、UDP和SCTP</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span>         <span class="comment"># Service自身的端口号</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span>   <span class="comment"># 目标端口号，即Endpoint上定义的端口号</span></span><br></pre></td></tr></table></figure>

<p>Service资源的spec.selector仅支持以映射（字典）格式定义的等值类型的标签选择器，例如上面示例中的app: demoapp。定义服务端口的字段spec.ports的值则是一个对象列表，它主要定义Service对象自身的端口与目标后端端口的映射关系。我们可以将示例中的Service对象创建于集群中，通过其详细描述了解其特性，如下面的命令及结果所示。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl apply -f services-clusterip-demo.yaml</span> </span><br><span class="line">service/demoapp-svc created</span><br><span class="line">~ $ kubectl describe services/demoapp-svc</span><br><span class="line">Name:              demoapp-svc</span><br><span class="line">Namespace:         default</span><br><span class="line">Labels:            &lt;none&gt;</span><br><span class="line">Annotations:       Selector:  app=demoapp</span><br><span class="line">Type:              ClusterIP</span><br><span class="line">IP:                10.97.72.1</span><br><span class="line">Port:              http  80/TCP</span><br><span class="line">TargetPort:        80/TCP</span><br><span class="line">Endpoints:         &lt;none&gt;</span><br><span class="line">Session Affinity:  None</span><br><span class="line">Events:            &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>上面命令中的结果显示，demoapp-svc默认设定为ClusterIP类型，并得到一个自动分配的IP地址10.97.72.1。创建Service对象的同时会创建一个与之同名且拥有相同标签选择器的Endpoint对象，若该标签选择器无法匹配到任何Pod对象的标签，则Endpoint对象无任何可用端点数据，于是Service对象的Endpoints字段值便成了<none>。<br>我们知道，Service对象自身只是iptables或ipvs规则，它并不能处理客户端的服务请求，而是需要把请求报文通过目标地址转换（DNAT）后转发至后端某个Server Pod，这意味着没有可用的后端端点的Service对象是无法响应客户端任何服务请求的，如下面从集群节点上发起的请求命令结果所示。</none></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mageedu@k8s-master01:~$ curl 10.97.72.1</span><br><span class="line">curl: (7) Failed to connect to 10.97.72.1 port 80: Connection refused</span><br></pre></td></tr></table></figure>

<p>下面使用命令式命令手动创建一个与该Service对象具有相同标签选择器的Deployment对象demoapp，它默认会自动创建一个拥有标签app: demoapp的Pod对象。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl create deploy demoapp --image=ikubernetes/demoapp:v1.0</span></span><br><span class="line">deployment.apps/demoapp created</span><br><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl get pods -l app=demoapp</span> </span><br><span class="line">NAME                READY   STATUS   RESTARTS   AGE</span><br><span class="line">demoapp-6c5d545684-g85gl   1/1     Running   0          8s</span><br></pre></td></tr></table></figure>

<p>Service对象demoapp-svc通过API Server获知这种匹配变动后，会立即创建一个以该Pod对象的IP和端口为列表项的名为demoapp-svc的Endpoints对象，而该Service对象详细描述信息中的Endpoint字段便以此列表项为值，如下面的命令结果所示。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl get endpoints/demoapp-svc</span></span><br><span class="line">NAME       ENDPOINTS     AGE</span><br><span class="line">demoapp-svc   10.244.2.7:80    42s</span><br><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl describe services/demoapp-svc | grep <span class="string">&quot;^Endpoints&quot;</span></span></span><br><span class="line">Endpoints:         10.244.2.7:80</span><br></pre></td></tr></table></figure>

<p>扩展Deployment对象demoapp的应用规模引起的变动也将立即反映到相关的Endpoint和Service对象之上，例如将deployments/demoapp对象的副本扩展至3个，再来验证services/demoapp-svc的端点信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl scale deployments/demoapp --replicas=3</span></span><br><span class="line">deployment.apps/demoapp scaled</span><br><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl get endpoints/demoapp-svc</span></span><br><span class="line">NAME          ENDPOINTS                       AGE</span><br><span class="line">demoapp-svc   10.244.1.11:80,10.244.2.7:80,10.244.3.9:80   96s</span><br><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl describe services/demoapp-svc | grep <span class="string">&quot;^Endpoints&quot;</span></span></span><br><span class="line">Endpoints:         10.244.1.11:80,10.244.2.7:80,10.244.3.9:80</span><br></pre></td></tr></table></figure>

<p>扩展Deployment对象demoapp的应用规模引起的变动也将立即反映到相关的Endpoint和Service对象之上，例如将deployments/demoapp对象的副本扩展至3个，再来验证services/demoapp-svc的端点信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl scale deployments/demoapp --replicas=3</span></span><br><span class="line">deployment.apps/demoapp scaled</span><br><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl get endpoints/demoapp-svc</span></span><br><span class="line">NAME          ENDPOINTS                       AGE</span><br><span class="line">demoapp-svc   10.244.1.11:80,10.244.2.7:80,10.244.3.9:80   96s</span><br><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl describe services/demoapp-svc | grep <span class="string">&quot;^Endpoints&quot;</span></span></span><br><span class="line">Endpoints:         10.244.1.11:80,10.244.2.7:80,10.244.3.9:80</span><br></pre></td></tr></table></figure>

<p>接下来可于集群中的某节点上再次向服务对象demoapp-svc发起访问请求以进行测试，多次的访问请求还可评估负载均衡算法的调度效果，如下面的命令及结果所示。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mageedu@k8s-master01:~$ while true; do curl -s 10.97.72.1/hostname; sleep .2; done</span><br><span class="line">ServerName: demoapp-6c5d545684-89w4f</span><br><span class="line">ServerName: demoapp-6c5d545684-zlm2w</span><br><span class="line">ServerName: demoapp-6c5d545684-g85gl</span><br><span class="line">ServerName: demoapp-6c5d545684-g85gl</span><br></pre></td></tr></table></figure>

<p><font color="red">kubeadm部署的Kubernetes集群的Service代理模型默认为iptables，它使用随机调度算法，因此Service会把客户端请求随机调度至其关联的某个后端Pod对象。请求取样次数越多，其调度效果也越接近算法的目标效果。</font></p>
<h3 id="应用NodePort-Service资源"><a href="#应用NodePort-Service资源" class="headerlink" title="应用NodePort Service资源"></a>应用NodePort Service资源</h3><p>部署Kubernetes集群系统时会预留一个端口范围，专用于分配给需要用到NodePort的Service对象，该端口范围默认为30000～32767。<font color="red">与Cluster类型的Service资源的一个显著不同之处在于，NodePort类型的Service资源需要显式定义.spec.type字段值为NodePort</font>，必要时还可以手动指定具体的节点端口号。例如下面的配置清单（services-nodeport-demo.yaml）中定义的Service资源对象demoapp-nodeport-svc，它使用了NodePort类型，且人为指定了32223这个节点端口。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">demoapp-nodeport-svc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">demoapp</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">nodePort:</span> <span class="number">32223</span></span><br></pre></td></tr></table></figure>

<p>实践中，并不鼓励用户自定义节点端口，除非能事先确定它不会与某个现存的Service资源产生冲突。无论如何，只要没有特别需要，留给系统自动配置总是较好的选择。将配置清单中定义的Service对象demoapp-nodeport-svc创建于集群之上，以便通过详细描述了解其状态细节。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl apply -f services-nodeport-demo.yaml</span> </span><br><span class="line">service/demoapp-nodeport-svc created</span><br><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl describe services demoapp-nodeport-svc</span>   </span><br><span class="line">Name:                     demoapp-nodeport-svc</span><br><span class="line">Namespace:                default</span><br><span class="line">Labels:                   &lt;none&gt;</span><br><span class="line">Annotations:              Selector:  app=demoapp</span><br><span class="line">Type:                     NodePort</span><br><span class="line">IP:                       10.97.227.67</span><br><span class="line">Port:                     http  80/TCP</span><br><span class="line">TargetPort:               80/TCP</span><br><span class="line">NodePort:                 http  32223/TCP</span><br><span class="line">Endpoints:                10.244.1.11:80,10.244.2.7:80,10.244.3.9:80</span><br><span class="line">Session Affinity:         None</span><br><span class="line">External Traffic Policy:  Cluster</span><br><span class="line">Events:                   &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>命令结果显示，该Service对象用于调度集群外部流量时使用默认的Cluster策略，该策略优先考虑负载均衡效果，哪怕目标Pod对象位于另外的节点之上而带来额外的网络跃点，因而针对该NodePort的请求将会被分散调度至该Serivce对象关联的所有端点之上。可以在集群外的某节点上对任一工作节点的NodePort端口发起HTTP请求以进行测试。以节点k8s-node03.ilinux.io为例，我们以如下命令向它的IP地址172.29.9.13的32223端口发起多次请求。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash"><span class="keyword">while</span> <span class="literal">true</span>; <span class="keyword">do</span> curl -s 172.29.9.13:32223; <span class="built_in">sleep</span> 1; <span class="keyword">done</span></span></span><br><span class="line">…… ClientIP: 10.244.3.1, ServerName: demoapp-6c5d545684-89w4f, ServerIP: 10.244.3.9!</span><br><span class="line">…… ClientIP: 10.244.3.0, ServerName: demoapp-6c5d545684-zlm2w, ServerIP: 10.244.1.11!</span><br><span class="line">…… ClientIP: 10.244.3.0, ServerName: demoapp-6c5d545684-g85gl, ServerIP: 10.244.2.7!</span><br></pre></td></tr></table></figure>

<p>上面命令的结果显示出外部客户端的请求被调度至该Service对象的每一个后端Pod之上，而这些Pod对象可能会分散于集群中的不同节点。命令结果还显示，请求报文的客户端IP地址是最先接收到请求报文的节点上用于集群内部通信的IP地址，而非外部客户端地址，这也能够在Pod对象的应用访问日志中得到进一步验证，如下所示。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl logs demoapp-6c5d545684-g85gl | <span class="built_in">tail</span> -n 1</span></span><br><span class="line">10.244.3.0 - - [31/Aug/2020 02:30:00] &quot;GET / HTTP/1.1&quot; 200 -</span><br></pre></td></tr></table></figure>

<p>NodePort类型的Service对象会对请求报文同时进行源地址转换（SNAT）和目标地址转换（DNAT）操作。<br>另一个外部流量策略Local则仅会将流量调度至请求的目标节点本地运行的Pod对象之上，以减少网络跃点，降低网络延迟，但当请求报文指向的节点本地不存在目标Service相关的Pod对象时将直接丢弃该报文。下面先把demoapp-nodeport-svc的外部流量策略修改为Local，而后再进行访问测试。简单起见，这里使用kubectl patch命令来修改Service对象的流量策略。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl patch services/demoapp-nodeport-svc -p <span class="string">&#x27;&#123;&quot;spec&quot;: &#123;&quot;externalTrafficPolicy&quot;: &quot;Local&quot;&#125;&#125;&#x27;</span></span>  </span><br><span class="line">service/demoapp-nodeport-svc patched</span><br></pre></td></tr></table></figure>

<p>-p选项中指定的补丁是一个JSON格式的配置清单片段，它引用了spec.externalTrafficPolicy字段，并为其赋一个新的值。配置完成后，我们再次发起测试请求时会看到，请求都被调度给了目标节点本地运行的Pod对象。另外，Local策略下无须在集群中转发流量至其他节点，也就不用再对请求报文进行源地址转换，Server Pod所看到的客户端IP就是外部客户端的真实地址。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash"><span class="keyword">while</span> <span class="literal">true</span>; <span class="keyword">do</span> curl -s 172.29.9.13:32223; <span class="built_in">sleep</span> 1; <span class="keyword">done</span></span>         </span><br><span class="line">…… ClientIP: 172.29.0.1, ServerName: demoapp-6c5d545684-89w4f, ServerIP: 10.244.3.9!</span><br><span class="line">…… ClientIP: 172.29.0.1, ServerName: demoapp-6c5d545684-89w4f, ServerIP: 10.244.3.9!</span><br><span class="line">…… ClientIP: 172.29.0.1, ServerName: demoapp-6c5d545684-89w4f, ServerIP: 10.244.3.9!</span><br></pre></td></tr></table></figure>

<p>NodePort类型的Service资源同样会被配置ClusterIP，以确保集群内的客户端对该服务的访问请求可在集群范围的通信中完成。</p>
<h3 id="应用LoadBalancer-Service资源"><a href="#应用LoadBalancer-Service资源" class="headerlink" title="应用LoadBalancer Service资源"></a>应用LoadBalancer Service资源</h3><p>NodePort类型的Service资源虽然能够在集群外部访问，但外部客户端必须事先得知NodePort和集群中至少一个节点IP地址，一旦被选定的节点发生故障，客户端还得自行选择请求访问其他的节点，因而一个有着固定IP地址的固定接入端点将是更好的选择。此外，集群节点很可能是某IaaS云环境中仅具有私有IP地址的虚拟主机，这类地址对互联网客户端不可达，为此类节点接入流量也要依赖于集群外部具有公网IP地址的负载均衡器，由其负责接入并调度外部客户端的服务请求至集群节点相应的NodePort之上。<br>IaaS云计算环境通常提供了LBaaS（Load Balancer as a Service）服务，它允许租户动态地在自己的网络创建一个负载均衡设备。部署在此类环境之上的Kubernetes集群可借助于CCM（Cloud Controller Manager）在创建LoadBalancer类型的Service资源时调用IaaS的相应API，按需创建出一个软件负载均衡器。但CCM不会为那些非LoadBalancer类型的Service对象创建负载均衡器，而且当用户将LoadBalancer类型的Service调整为其他类型时也将删除此前创建的负载均衡器。<font color="red">kubeadm在部署Kubernetes集群时并不会默认部署CCM，有需要的用户需要自行部署。</font><br>对于没有此类API可用的Kubernetes集群，管理员也可以为NodePort类型的Service手动部署一个外部的负载均衡器（推荐使用HA配置模型），并配置将请求流量调度至各节点的NodePort之上，这种方式的缺点是管理员需要手动维护从外部负载均衡器到内部服务的映射关系。<br>从实现方式上来说，LoadBalancer类型的Service就是在NodePort类型的基础上请求外部管理系统的API，并在Kubernetes集群外部额外创建一个负载均衡器，将流量调度至该NodePort Service之上。Kubernetes以异步方式请求创建负载均衡器，并将有关配置保存在Service对象的.status.loadBalancer字段中。下面是定义在services-loadbalancer-demo.yam配置清单中的LoadBalancer类型Service资源，在最简单的配置模型中，用户仅需要修改NodePort Service服务定义中type字段的值为LoadBalancer即可。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">demoapp-loadbalancer-svc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">LoadBalancer</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">demoapp</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>Service对象的loadBalancerIP负责承接外部发来的流量，该IP地址通常由云服务商系统动态配置，或者借助.spec.loadBalancerIP字段显式指定，但有些云服务商不支持用户设定该IP地址，这种情况下，即便提供了也会被忽略。外部负载均衡器的流量会直接调度至Service后端的Pod对象之上，而如何调度流量则取决于云服务商，有些环境可能还需要为Service资源的配置定义添加注解，必要时请自行参考云服务商文档说明。另外，LoadBalancer Service还支持使用.spec. loadBalancerSourceRanges字段指定负载均衡器允许的客户端来源的地址范围。</p>
<h3 id="外部IP"><a href="#外部IP" class="headerlink" title="外部IP"></a>外部IP</h3><p>若集群中部分或全部节点除了有用于集群通信的节点IP地址之外，还有可用于外部通信的IP地址，如图7-10中的EIP-1和EIP-2，那么我们还可以在Service资源上启用spec.externalIPs字段来基于这些外部IP地址向外发布服务。所有路由到指定的外部IP（externalIP）地址某端口的请求流量都可由该Service代理到后端Pod对象之上，如图7-10所示。从这个角度来说，请求流量到达外部IP与节点IP并没有本质区别，但外部IP却可能仅存在于一部分的集群节点之上，而且它不受Kubernetes集群管理，需要管理员手动介入其配置和回收等操作任务中。</p>
<p><img src="/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123132640583.png" alt="image-20220123132640583"></p>
<p>外部IP地址可结合ClusterIP、NodePort或LoadBalancer任一类型的Service资源使用，而到达外部IP的请求流量会直接由相关联的Service调度转发至相应的后端Pod对象进行处理。假设示例Kubernetes集群中的k8s-node01节点上拥有一个可被路由到的IP地址172.29.9.26，我们期望能够将demoapp的服务通过该外部IP地址发布到集群外部，则可以使用下列配置清单（services-externalip-demo.yaml）中的Service资源实现。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">demoapp-externalip-svc</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">demoapp</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">externalIPs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="number">172.29</span><span class="number">.9</span><span class="number">.26</span></span><br></pre></td></tr></table></figure>

<p>节点k8s-node01故障也必然导致该外部IP上公开的服务不再可达，除非该IP地址可以浮动到其他节点上。如今，大多数云服务商都支持浮动IP的功能，该IP地址可绑定在某个主机，并在其故障时通过某种触发机制自动迁移至其他主机。在不具有浮动IP功能的环境中进行测试之前，需要先在k8s-node01上（或根据规划的其他的节点上）手动配置172.29.9.26这个外部IP地址。而且，在模拟节点故障并手动将外部IP地址配置在其他节点进行浮动IP测试时，还需要清理之前的ARP地址缓存。</p>
<h2 id="Service与Endpoint资源"><a href="#Service与Endpoint资源" class="headerlink" title="Service与Endpoint资源"></a>Service与Endpoint资源</h2><p>端点是指通过LAN或WAN连接的能够用于网络通信的硬件设备，它在广义上可以指代任何与网络连接的设备。在Kubernetes语境中，端点通常代表Pod或节点上能够建立网络通信的套接字，并由专用的资源类型Endpoint进行定义和跟踪。</p>
<h3 id="Endpoint与容器探针"><a href="#Endpoint与容器探针" class="headerlink" title="Endpoint与容器探针"></a>Endpoint与容器探针</h3><p>Service对象借助于Endpoint资源来跟踪其关联的后端端点，但Endpoint是“二等公民”，<font color="red">Service对象可根据标签选择器直接创建同名的Endpoint对象</font>，不过用户几乎很少有直接使用该类型资源的需求。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">services-readiness-demo</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">demoapp-with-readiness</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span>      <span class="comment"># 定义Deployment对象，它使用Pod模板创建Pod对象</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">demoapp2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span>         <span class="comment"># 该Deployment对象要求满足的Pod对象数量</span></span><br><span class="line">  <span class="attr">selector:</span>           <span class="comment"># Deployment对象的标签选择器，用于筛选Pod对象并完成计数</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">demoapp-with-readiness</span></span><br><span class="line">  <span class="attr">template:</span>           <span class="comment"># 由Deployment对象使用的Pod模板，用于创建足额的Pod对象</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">demoapp-with-readiness</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">ikubernetes/demoapp:v1.0</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">demoapp</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">readinessProbe:</span></span><br><span class="line">          <span class="attr">httpGet:</span>    <span class="comment"># 定义探针类型和探测方式</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">&#x27;/readyz&#x27;</span></span><br><span class="line">            <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">initialDelaySeconds:</span> <span class="number">15</span>   <span class="comment"># 初次检测延迟时长</span></span><br><span class="line">          <span class="attr">periodSeconds:</span> <span class="number">10</span>         <span class="comment"># 检测周期</span></span><br></pre></td></tr></table></figure>

<p>Endpoint对象会根据就绪状态把同名Service对象标签选择器筛选出的后端端点的IP地址分别保存在subsets.addresses字段和subsets.notReadyAddresses字段中，通过API Server持续、动态跟踪每个端点的状态变动，并即时反映到端点IP所属的字段。仅那些位于subsets.addresses字段的端点地址可由相关的Service用作后端端点。此外，相关Service对象标签选择器筛选出的Pod对象数量的变动也将会导致Endpoint对象上的端点数量变动。<br>上面配置清单中定义Endpoint对象services-readiness-demo会筛选出Deployment对象demoapp2创建的两个Pod对象，将它们的IP地址和服务端口创建为端点对象。但延迟15秒启动的容器探针会导致这两个Pod对象至少要在15秒以后才能转为“就绪”状态，这意味着在上面配置清单中的Service资源创建后至少15秒之内无可用后端端点，例如下面的资源创建和Endpoint资源监视命令结果中，在20秒之后，Endpoint资源services-readiness-demo才得到第一个可用的后端端点IP。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl apply -f services-readiness-demo.yaml</span> </span><br><span class="line">service/services-readiness-demo created</span><br><span class="line">deployment.apps/demoapp2 created</span><br><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl get endpoints/services-readiness-demo -w</span> </span><br><span class="line">NAME                      ENDPOINTS                      AGE</span><br><span class="line">services-readiness-demo                                  6s</span><br><span class="line">services-readiness-demo   10.244.1.15:80                 20s</span><br><span class="line">services-readiness-demo   10.244.1.15:80,10.244.2.9:80   31s</span><br></pre></td></tr></table></figure>

<p>因任何原因导致的后端端点就绪状态检测失败，都会触发Endpoint对象将该端点的IP地址从subsets.addresses字段移至subsets.notReadyAddresses字段。例如，我们使用如下命令人为地将地址10.244.2.9的Pod对象中的容器就绪状态检测设置为失败，以进行验证。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">curl -s -X POST -d <span class="string">&#x27;readyz=FAIL&#x27;</span> 10.244.2.9/readyz</span></span><br></pre></td></tr></table></figure>

<p>等待至少3个检测周期共30秒之后，获取Endpoint对象services-readiness-demo的资源清单的命令将返回类似如下信息。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl get endpoints/services-readiness-demo -o yaml</span></span><br><span class="line">……</span><br><span class="line">subsets:</span><br><span class="line">- addresses:</span><br><span class="line">  - ip: 10.244.1.15</span><br><span class="line">    nodeName: k8s-node01.ilinux.io</span><br><span class="line">    targetRef:</span><br><span class="line">      kind: Pod</span><br><span class="line">      name: demoapp2-85595465d-dhbzs</span><br><span class="line">      namespace: default</span><br><span class="line">      resourceVersion: &quot;321388&quot;</span><br><span class="line">      uid: 8d2a3bb6-c628-4558-917a-f8f6df9b8573</span><br><span class="line">  notReadyAddresses:</span><br><span class="line">  - ip: 10.244.2.9</span><br><span class="line">    nodeName: k8s-node02.ilinux.io</span><br><span class="line">    targetRef:</span><br><span class="line">      kind: Pod</span><br><span class="line">      name: demoapp2-85595465d-z7w5h</span><br><span class="line">      namespace: default</span><br><span class="line">      resourceVersion: &quot;323328&quot;</span><br><span class="line">      uid: 380050ae-4e32-4724-af22-e079ab2ec02e</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    protocol: TCP</span><br></pre></td></tr></table></figure>

<p>该故障端点重新转回就绪状态后，Endpoints对象会将其移回subsets.addresses字段中。这种处理机制确保了Service对象不会将客户端请求流量调度给那些处于运行状态但服务未就绪（notReady）的端点。</p>
<h3 id="自定义Endpoint资源"><a href="#自定义Endpoint资源" class="headerlink" title="自定义Endpoint资源"></a>自定义Endpoint资源</h3><p>除了借助Service对象的标签选择器自动关联后端端点外，Kubernetes也支持自定义Endpoint对象，用户可通过配置清单创建具有固定数量端点的Endpoint对象，而调用这类Endpoint对象的同名Service对象无须再使用标签选择器。Endpoint资源的API规范如下。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Endpoint</span></span><br><span class="line"><span class="attr">metadata:</span>                  <span class="comment"># 对象元数据</span></span><br><span class="line">  <span class="attr">name:</span></span><br><span class="line">  <span class="attr">namespace:</span></span><br><span class="line"><span class="attr">subsets:</span>                   <span class="comment"># 端点对象的列表</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">addresses:</span>               <span class="comment"># 处于“就绪”状态的端点地址对象列表</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hostname</span>  <span class="string">&lt;string&gt;</span>     <span class="comment"># 端点主机名</span></span><br><span class="line">    <span class="string">ip</span> <span class="string">&lt;string&gt;</span>            <span class="comment"># 端点的IP地址，必选字段</span></span><br><span class="line">    <span class="string">nodeName</span> <span class="string">&lt;string&gt;</span>      <span class="comment"># 节点主机名</span></span><br><span class="line">    <span class="string">targetRef：</span>            <span class="comment"># 提供了该端点的对象引用</span></span><br><span class="line">      <span class="string">apiVersion</span> <span class="string">&lt;string&gt;</span>  <span class="comment"># 被引用对象所属的API群组及版本</span></span><br><span class="line">      <span class="string">kind</span> <span class="string">&lt;string&gt;</span>        <span class="comment"># 被引用对象的资源类型，多为Pod</span></span><br><span class="line">      <span class="string">name</span> <span class="string">&lt;string&gt;</span>        <span class="comment"># 对象名称</span></span><br><span class="line">      <span class="string">namespace</span> <span class="string">&lt;string&gt;</span>   <span class="comment"># 对象所属的名称空间</span></span><br><span class="line">      <span class="string">fieldPath</span> <span class="string">&lt;string&gt;</span>   <span class="comment"># 被引用的对象的字段，在未引用整个对象时使用，通常仅引用</span></span><br><span class="line">                           <span class="comment"># 指定Pod对象中的单容器，例如spec.containers[1]</span></span><br><span class="line">      <span class="string">uid</span> <span class="string">&lt;string&gt;</span>         <span class="comment"># 对象的标识符</span></span><br><span class="line">  <span class="attr">notReadyAddresses:</span>       <span class="comment"># 处于“未就绪”状态的端点地址对象列表，格式与address相同</span></span><br><span class="line">  <span class="attr">ports:</span>                   <span class="comment"># 端口对象列表</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">name</span> <span class="string">&lt;string&gt;</span>          <span class="comment"># 端口名称</span></span><br><span class="line">    <span class="string">port</span> <span class="string">&lt;integer&gt;</span>         <span class="comment"># 端口号，必选字段</span></span><br><span class="line">    <span class="string">protocol</span> <span class="string">&lt;string&gt;</span>      <span class="comment"># 协议类型，仅支持UDP、TCP和SCTP，默认为TCP</span></span><br><span class="line">    <span class="string">appProtocol</span> <span class="string">&lt;string&gt;</span>   <span class="comment"># 应用层协议</span></span><br></pre></td></tr></table></figure>

<p>自定义Endpoint常将那些不是由编排程序编排的应用定义为Kubernetes系统的Service对象，从而让客户端像访问集群上的Pod应用一样请求外部服务。例如，假设要把Kubernetes集群外部一个可经由172.29.9.51:3306或172.29.9.52:3306任一端点访问的MySQL数据库服务引入集群中，便可使用如下清单中的配置完成。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Endpoints</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-external</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">subsets:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">addresses:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">ip:</span> <span class="number">172.29</span><span class="number">.9</span><span class="number">.51</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">ip:</span> <span class="number">172.29</span><span class="number">.9</span><span class="number">.52</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">3306</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-external</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">3306</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">3306</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure>

<p>显然，非经Kubernetes管理的端点，其就绪状态难以由Endpoint通过注册监视特定的API资源对象进行跟踪，因而用户需要手动维护这种调用关系的正确性。<br>Endpoint资源提供了在Kubernetes集群上跟踪端点的简单途径，但对于有着大量端点的Service来说，将所有的网络端点信息都存储在单个Endpoint资源中，会对Kubernetes控制平面组件产生较大的负面影响，且每次端点资源变动也会导致大量的网络流量。EndpointSlice（端点切片）通过将一个服务相关的所有端点按固定大小（默认为100个）切割为多个分片，提供了一种更具伸缩性和可扩展性的端点替代方案。<br>EndpointSlice由引用的端点资源组成，类似于Endpoint，它可由用户手动创建，也可由EndpointSlice控制器根据用户在创建Service资源时指定的标签选择器筛选集群上的Pod对象自动创建。单个EndpointSlice资源默认不能超过100个端点，小于该数量时，EndpointSlice与Endpoint存在1:1的映射关系且性能相同。EndpointSlice控制器会尽可能地填满每一个EndpointSlice资源，但不会主动进行重新平衡，新增的端点会尝试添加到现有的EndpointSlice资源上，若超出现有任何EndpointSlice对象的可用的空余空间，则将创建新的EndpointSlice，而非分散填充。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl get endpointslice -n kube-system</span></span><br><span class="line">NAME           ADDRESSTYPE        PORTS            ENDPOINTS        AGE</span><br><span class="line">kube-dns-mbdj5   IPv4          53,9153,53   10.244.0.6,10.244.0.7   13d</span><br></pre></td></tr></table></figure>

<p>EndpointSlice资源根据其关联的Service与端口划分成组，每个组隶属于同一个Service。更具体的使用方式请参考Kubernetes的相关文档。</p>
<h2 id="深入理解Service资源"><a href="#深入理解Service资源" class="headerlink" title="深入理解Service资源"></a>深入理解Service资源</h2><p>本质上，Service对象代表着由kube-proxy借助于自身的程序逻辑（userspace）、iptables或ipvs，甚至是某种形式的组合所构建出的流量代理和调度转发机制，每个Service对象的创建、更新与删除都会经由kube-proxy反映为程序配置、iptables规则或ipvs规则的相应操作。</p>
<h3 id="iptables代理模型-1"><a href="#iptables代理模型-1" class="headerlink" title="iptables代理模型"></a>iptables代理模型</h3><p>由集群中每个节点上的kube-proxy进程将Service定义、转换且配置于节点内核上的iptables规则。每个Service的定义主要由Service流量匹配规则、流量调度规则和以每个后端Endpoint为单位的DNAT规则组成，这些规则负责完成Service资源的核心功能。此外，iptables代理模型还会额外在filter表和mangle表上使用一些辅助类的规则。</p>
<h4 id="ClusterIP-Service"><a href="#ClusterIP-Service" class="headerlink" title="ClusterIP Service"></a>ClusterIP Service</h4><p>ClusterIP类型Service资源的请求流量是指以某个特定Service对象的ClusterIP（或称为Service_IP）为目标地址，同时以Service_Port为目标端口的报文，它们可能源自Kubernetes集群中某个特定节点上的Pod、独立容器（非托管至Kubernetes集群）或进程，也可能源自节点之外。通常，源自独立容器或节点外部的请求报文的源IP地址为Pod网络（例如Flannel默认的10.244.0.0/16）之外的IP地址。<br>Cluster类型Service对象的相关规则主要位于KUBE-SERVICES、KUBE-MARQ-MASK和KUBE-POSTROUTING这3个自定义链，以及那些以KUBE-SVC或KUBE-SEP为前缀的各个自定义链上，用于实现Service流量筛选、分发和目标地址转换（端点地址），以及为非源自Pod网络的请求报文进行源地址转换。各相关的规则链及调用关系如图7-11所示。</p>
<p><img src="/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123133725398.png" alt="image-20220123133725398"></p>
<p>▪KUBE-SERVICES：包含所有ClusterIP类型Service的流量匹配规则，由PREROUTING和OUTPUT两个内置链直接调用。每个Service对象包含两条规则定义，对于所有发往该Service（目标IP为Service_IP且目标端口为Service_Port）的请求报文：前一条规则用于为非源自Pod网络（! -s 10.244.0.0/16）中的请求报文打上特有的防火墙标记，而打标签的操作则要借助KUBE-MARQ-MASK自定义链中的规则，后一条规则负责将所有报文转至专用的以KUBE-SVC为名称前缀的自定义链，后缀是Service信息的HASH值。<br>▪KUBE-MARQ-MASK：专用目的自定义链，所有转至该自定义链的报文都将被打上特有的防火墙标记（0x4000），以便于将特定类型的报文定义为单独的分类，进而在将该类报文转发到目标端点之前由POSTROUTING规则链进行源地址转换。<br>▪KUBE-SVC-<HASH>：定义一个服务的流量调度规则，它通过随机调度算法将请求分发给该Service的所有后端端点，每个后端端点定义在以KUBE-SEP为前缀名称的自定义链上，后缀是端点信息的hash值。<br>▪KUBE-SEP-<HASH>：定义一个端点相关的流量处理规则。它通常包含两条规则：前一条用于为那些源自该端点自身（-s ep_ip）的流量请求调用自定义链KUBE-MARQ-MASK，打上特有的防火墙标记；后一条负责对发往该端点的所有流量进行目标IP地址和端口转换，新目标为该端点的IP和端口（-j DNAT –to-destination ep_ip:ep_port）。<br>▪KUBE-POSTROUTING：专用的自定义链，由内置链POSTROUTING无条件调用，负责对带特有防火墙标记0x4000的请求报文进行源地址转换或地址伪装（MASQUERADE），新的源地址为报文离开协议栈时流经接口的主IP地址。<br>我们可通过实际存在的Service对象来验证这些设定，以7.2.1节创建的demoapp-svc为例，在集群中的任何一个工作节点上使用iptables -t nat -vnL或iptables -t nat -S命令打印与它相关的iptables规则。下面的命令打印了该Service对象用于流量匹配的相关规则，它定义在KUBE-SERVICES自定义链上。</HASH></HASH></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node01:~# iptables -t nat -S KUBE-SERVICES | grep &quot;default/demoapp-svc&quot;</span><br><span class="line">-A KUBE-SERVICES ! -s 10.244.0.0/16 -d 10.97.72.1/32 -p tcp -m comment --comment &quot;default/demoapp-svc:http cluster IP&quot; -m tcp --dport 80 -j KUBE-MARK-MASQ</span><br><span class="line">-A KUBE-SERVICES -d 10.97.72.1/32 -p tcp -m comment --comment &quot;default/demoapp-svc:http cluster IP&quot; -m tcp --dport 80 -j KUBE-SVC-ZAGXFVDPX7HH4UMW</span><br></pre></td></tr></table></figure>

<p>第一条规则用于将那些发往demoapp-svc的、来自10.244.0.0/16网络之外的请求报文交由自定义链KUBE-MARK-MASQ上的规则添加专用标记0x4000，该条规则如下所示。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node01:~# iptables -t nat -S KUBE-MARK-MASQ | grep &quot;^-A&quot;</span><br><span class="line">-A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000</span><br></pre></td></tr></table></figure>

<p>添加标记的处理并不会短路iptables规则链KUBE-SERVICES对流量的处理，因此所有发往demoapp-svc的流量还会继续由后一条规则指向的、以KUBE-SVC为名称前缀的自定义链KUBE-SVC-ZAGXFVDPX7HH4UMW中的规则处理。该自定义链专用于为demoapp-svc中的所有可用端点定义流量调度规则，它包含如下3条规则：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node01:~# iptables -t nat -S KUBE-SVC-ZAGXFVDPX7HH4UMW | grep &quot;^-A&quot; </span><br><span class="line">-A KUBE-SVC-ZAGXFVDPX7HH4UMW -m comment --comment &quot;default/demoapp-svc:http&quot; -m statistic --mode random --probability 0.33333333349 -j KUBE-SEP-HDIVJIPCJU2JBJVX</span><br><span class="line">-A KUBE-SVC-ZAGXFVDPX7HH4UMW -m comment --comment &quot;default/demoapp-svc:http&quot; -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-ZAFCYSF77K72PY72</span><br><span class="line">-A KUBE-SVC-ZAGXFVDPX7HH4UMW -m comment --comment &quot;default/demoapp-svc:http&quot; -j KUBE-SEP-FUO5ALUGHUE426HZ</span><br></pre></td></tr></table></figure>

<p>注意<br>所有以KUBE-SEP和KUBE-SVC为前缀的自定义链的名称在重新创建Service或重启Kubernetes集群后都有可能发生改变，但它们的引用关系不变。</p>
<p>这3条规则的处理目标分别为3个以KUBE-SEP为名称前缀的自定义链，每个链上定义了一个端点的流量处理规则，因而意味着该Service对象共有3个Endpoint对象，所有流量将在这3个Endpoint之间随机（–mode random）分配。到达KUBE-SVC-ZAGXFVDPX7HH4UMW的流量将由这3条规则以“短路”方式进行匹配检查和处理，任何一条规则处理后都不会再匹配后续的其他规则。第一条规则将处理大约1/3（–probability 0.33333333349）的流量，余下的所有流量（即由第一条规则处理后余下的2/3）将由第二条规则处理一半（–probability 0.50000000000），再余下的所有流量都将由第三条规则处理，因此3个Endpoint将各自得到大约1/3的流量。<br>每个Endpoint专用的自定义链以KUBE-SEP为名称前缀，它包含某单点端点相关的流量处理规则。以专用IP地址为10.244.1.11的Endpoint对象为例，它对应于自定义链KUBE-SEP-HZPGLN57HG6GZW4O，该链下包含两个iptables规则，如下面的命令结果所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node01:~#  iptables -t nat -S KUBE-SEP-HDIVJIPCJU2JBJVX | grep &quot;^-A&quot;                         </span><br><span class="line">-A KUBE-SEP-HDIVJIPCJU2JBJVX -s 10.244.1.11/32 -m comment --comment &quot;default/demoapp-svc:http&quot; -j KUBE-MARK-MASQ</span><br><span class="line">-A KUBE-SEP-HDIVJIPCJU2JBJVX -p tcp -m comment --comment &quot;default/demoapp-svc:http&quot; -m tcp -j DNAT --to-destination 10.244.1.11:80</span><br></pre></td></tr></table></figure>

<p>Pod对象也可能会向自己所属的Service对象发起访问请求，而且该请求经由OUTPUT链到达KUBE-SERVICES链后存在被调度回当前Pod对象的可能性。第一条规则就是为该类报文添加专有的流量标记。第二条规则将接收到的所有流量进行目标地址转换（DNAT），新的目标为10.244.1.11:80，它对应Kubernetes集群上由Service对象demoapp-svc匹配到的一个特定Pod对象。<br>不难猜测，特定节点（例如前面示例中的k8s-node01）接收到的请求报文的源地址为Pod网络中的IP地地址的，必然源自该节点或节点上的Pod对象。它们的IP地址位于该节点的PodCIDR之中，这些流量离开节点之前无须进行源地址转换，因而目标端点直接响应给客户端IP就能够正确到达请求方。而请求报文的源地址并非为Pod网络中的IP地址的，例如请求方为该节点上的某独立容器，则Service必须在其离开本节点之前，将请求报文的源地址转换为该节点上报文离开时要经由接口的IP地址（例如cni0上的10.244.1.0），以确保响应报文可正确回送至该节点，并由该节点响应给相应的客户端，由内置链POSTROUTING所调用的自定义链KUBE-POSTROUTING上的规则便用于实现此类功能。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node01:~# iptables -t nat -S KUBE-POSTROUTING | grep &quot;^-A&quot;</span><br><span class="line">-A KUBE-POSTROUTING -m comment --comment &quot;kubernetes service traffic requiring SNAT&quot; -m mark --mark 0x4000/0x4000 -j MASQUERADE</span><br></pre></td></tr></table></figure>

<p>由此可见，对于集群内部的后端端点来说，它们收到的请求报文的源地址，要么是Pod的IP地址，要么是节点IP地址，因而直接发送响应报文给请求方即可。但那些本身并非源自Pod或节点的请求的响应报文，还需要由节点自动执行一次目标地址转换，以便把报文送达真正的请求方。注意<br>kube-proxy也支持在iptables代理模型上使用masquerade all，从而对通过ClusterIP地址访问的所有请求进行源地址转换，但在大多数场景中，这都不是必要的选择。2. NodePort Service<br>相较于ClusterIP类型来说，所有发往NodePort类型的Service对象的请求流量的目标IP和端口分别是节点IP和NodePort，这类报文无法由KUBE-SERVICES自定义链上那些基于Service IP和Service Port定义的流量匹配规则所匹配，但会由该自定义链上的最后一条规则转给KUBE-NODEPORTS自定义链。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node01:~# iptables -t nat -S KUBE-SERVICES | tail -n 1</span><br><span class="line">-A KUBE-SERVICES -m comment --comment &quot;kubernetes service nodeports; NOTE: this must be the last rule in this chain&quot; -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS</span><br></pre></td></tr></table></figure>

<p>KUBE-NODEPORTS链以类似ClusterIP Service拦截规则的方式定义了NodePort Service对象的拦截规则，其中每个Service对象包含两条规则定义。对于所有发往该Service（目标IP为该NodeIP，目标端口为NodePort）的请求报文：前一条规则为发往该Service对象的所有请求报文，基于KUBE-MARQ-MASK自定义链中的规则打上特有的防火墙标记；后一条规则负责将这些报文转至专用的、以KUBE-SVC为前缀的自定义链。以前面创建的demoapp-nodeport-svc为例，它拥有以下两条iptables规则。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node01:~#  iptables -t nat -S KUBE-NODEPORTS | grep &quot;default/demoapp-nodeport-svc&quot;</span><br><span class="line">-A KUBE-NODEPORTS -p tcp -m comment --comment &quot;default/demoapp-nodeport-svc:http&quot; -m tcp --dport 31398 -j KUBE-MARK-MASQ</span><br><span class="line">-A KUBE-NODEPORTS -p tcp -m comment --comment &quot;default/demoapp-nodeport-svc:http&quot; -m tcp --dport 31398 -j KUBE-SVC-HCTPASJ7WVWOBYLM</span><br></pre></td></tr></table></figure>

<p>我们已经知道，Service对象的专用自定义链定义了一组调度规则，以调度发往该Service对象匹配的所有后端端点的相关流量，而其中的每一个后端端点又有自己专用的自定义链，用于对请求报文进行目标地址转换。另外，NodePort类型的Service为所有从NodePort进入的请求报文都打了特有防火墙标记，因此这些请求报文会按照POSTROUTING和KUBE-POSTROUTING链上的规则将源地址转换为该报文离开节点时所经由的接口的IP地址。这些处理步骤与ClusterIP类型的Service对象几乎完全相同。完整的处理流程如图7-12所示。</p>
<p><img src="/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123134247463.png" alt="image-20220123134247463"></p>
<p>对于集群内部的后端端点来说，它们收到的请求报文的源地址都是节点IP地址。以Flannel插件环境中10.244.1.0/24这个Pod CIDR为例，该IP地址可能是flannel.1接口上的10.244.1.0/24，也可能是cni0上的10.244.1.1/24。于是，后端端点会把报文响应给请求报文进入时的节点，再由该节点将目标地址转换为客户端IP后发送。<br>但是，对于将外部流量策略定义为Local的NodePort Service对象来说，由于流量报文不会在集群内跨节点转发，也就没有必要对请求报文进行SNAT操作，所以后端端点可以看到真实的客户端IP。它的具体处理流程如图7-13所示。<br><img src="/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123134329215.png" alt="image-20220123134329215"></p>
<p>1）KUBE-SERVICES链把目标地址指向当前节点的报文，并转给KUBE-NODEPORTS处理。<br>2）对于一个Local策略的NodePort Service来说，KUBE-NODEPORTS会定义两条规则：前一条负则将源地址位于127.0.0.0/8网络的请求报文借助KUBE-MARK-MASQ打上0x4000防火墙标记；后一条则将报文转给该Service专用的KUBE-XLB-<HASH>自定义链。<br>3）KUBE-XLB-<HASH>自定义链将源自Pod网络（10.244.0.0/16）的请求报文以类似ClusterIP Service使用的方式进行处理，只转换请求报文目标地址；将源自当前节点所处的本地网络中的请求报文，按照常规的NodePort Service使用的方式进行处理，并同时转换源地址和目标地址；而将其他类型的请求报文直接转交给指定的本地后端端点处理，这也体现了本地流量策略的真正意义。<br>显然，若某节点自身未运行NodePort Service后端Pod，则本地策略类型的请求将得到失败的响应结果。提示<br>未配置外部IP地址的LoadBalancer类型的Service对象的工作方式与NodePort类型几乎完全相同，这里不再专门描述。3. External IP<br>在iptables中，外部IP表现为一种专有的Service访问入口。在KUBE-SERVICES自定义链上，每个外部IP都有3条相关的iptables规则：第1条用于为发往该外部IP的服务端口的请求流量，借助KUBE-MARK-MASQ自定义链打上特有的防火墙标记0x4000；第2条将这些请求流量中从非物理接口进入且源地址类型不是本地地址的流量，交由相应Service的专用自定义链进行流量分发；第3条用于将这些流量中目标地址类型是本地地址的请求报文，也交由相应Service的专用自定义链进行流量分发。具体的处理过程如图7-14所示。</HASH></HASH></p>
<p><img src="/blog/2022/02/09/Service%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20220123134355773.png" alt="image-20220123134355773"></p>
<p>以前面定义的default/demoapp-externalip-svc中使用的外部IP 172.29.9.26为例，下面的命令可以在KUBE-SERVICES获取到相应的专用规则。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node01:~# iptables -t nat -S KUBE-SERVICES | grep &quot;172.29.9.26&quot;           </span><br><span class="line">-A KUBE-SERVICES -d 172.29.9.26/32 -p tcp -m comment --comment &quot;default/demoapp-externalip-svc:http external IP&quot; -m tcp --dport 80 -j KUBE-MARK-MASQ</span><br><span class="line">-A KUBE-SERVICES -d 172.29.9.26/32 -p tcp -m comment --comment &quot;default/demoapp-externalip-svc:http external IP&quot; -m tcp --dport 80 -m physdev ! --physdev-is-in -m addrtype ! --src-type LOCAL -j KUBE-SVC-PX62EIGZ4HAB6Y56</span><br><span class="line">-A KUBE-SERVICES -d 172.29.9.26/32 -p tcp -m comment --comment &quot;default/demoapp-externalip-svc:http external IP&quot; -m tcp --dport 80 -m addrtype --dst-type LOCAL -j KUBE-SVC-PX62EIGZ4HAB6Y56</span><br></pre></td></tr></table></figure>

<p>由此可见，尽管外部IP需要结合ClusterIP、NodePort或LoadBalancer中任一类型的Service对象使用，但到达外部IP的服务请求流量却有着专用的拦截规则，请求报文也是交由相应Service的专用自定义链直接进行向后分发。</p>
<h3 id="ipvs代理模型-1"><a href="#ipvs代理模型-1" class="headerlink" title="ipvs代理模型"></a>ipvs代理模型</h3><p>由前一节的介绍可知，单个Service对象的iptables数量与后端端点的数量正相关，对于拥有较多Service对象和大规模Pod对象的Kubernetes集群，每个节点的内核上将充斥着大量的iptables规则。Service对象的变动会导致所有节点刷新netfilter上的iptables规则，而且每次的Service请求也都将经历多次的规则匹配检测和处理过程，这会占用节点上相当比例的系统资源。因此，iptables代理模型不适用于Service和Pod数量较多的集群。ipvs代理模型通过将流量匹配和分发功能配置为少量ipvs规则，有效降低了对系统资源的占用，从而能够承载更大规模的Kubernetes集群。</p>
<ol>
<li>调整kube-proxy代理模型<br>kube-proxy使用的代理模型定义在配置文件中，kubeadm部署的Kubernetes集群以DaemonSet控制器编排kube-proxy在每个节点上运行一个实例，配置文件则以kube-system名称空间中名为kube-proxy的ConfigMap对象的形式提供，默认使用iptables代理模型。在测试集群环境中，可直接使用kubectl edit configmaps/kube-proxy -n kube-system命令编辑该ConfigMap对象，将代理模型修改为ipvs，配置要点如下所示。</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">config.conf:</span> <span class="string">|-</span></span><br><span class="line"><span class="string">    apiVersion: kubeproxy.config.k8s.io/v1alpha1</span></span><br><span class="line"><span class="string">    bindAddress: 0.0.0.0</span></span><br><span class="line"><span class="string">    ……</span></span><br><span class="line"><span class="string">    iptables:                 # iptables配置细节</span></span><br><span class="line"><span class="string">      masqueradeAll: false    # 是否将通过ClusterIP访问的流量全部进行SNAT</span></span><br><span class="line"><span class="string">      masqueradeBit: null</span></span><br><span class="line"><span class="string">      minSyncPeriod: 0s</span></span><br><span class="line"><span class="string">      syncPeriod: 0s</span></span><br><span class="line"><span class="string">    ipvs:                     # ipvs配置细节</span></span><br><span class="line"><span class="string">      excludeCIDRs: null</span></span><br><span class="line"><span class="string">      minSyncPeriod: 0s</span></span><br><span class="line"><span class="string">      scheduler: &quot;&quot;           # 调度算法，默认为rr</span></span><br><span class="line"><span class="string">      strictARP: false</span></span><br><span class="line"><span class="string">      syncPeriod: 0s</span></span><br><span class="line"><span class="string">      tcpFinTimeout: 0s</span></span><br><span class="line"><span class="string">      tcpTimeout: 0s</span></span><br><span class="line"><span class="string">      udpTimeout: 0s</span></span><br><span class="line"><span class="string">    kind: KubeProxyConfiguration</span></span><br><span class="line"><span class="string">    metricsBindAddress: &quot;&quot;</span></span><br><span class="line"><span class="string">    mode: &quot;ipvs&quot;              # 代理模型，空值代表是iptables</span></span><br><span class="line"><span class="string">    nodePortAddresses: null</span></span><br><span class="line"><span class="string">    ……</span></span><br></pre></td></tr></table></figure>

<p>配置完成后，以灰度模式手动逐个或分批次删除kube-system名称空间中kube-proxy旧版本的Pod实例，全部更新完成后便切换到了ipvs代理模型。或者，在测试环境中，可以直接使用如下命令一次性完成所有实例的强制更新。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl delete pods -l k8s-app=kube-proxy -n kube-system</span></span><br></pre></td></tr></table></figure>

<p>提示<br>用于生产环境时，建议在部署Kubernetes集群时直接选定要使用的代理模型，或在集群部署完成后立即调整代理模型，而后再部署其他应用。</p>
<ol start="2">
<li>ipvs代理模型下的Service资源<br>相较于iptables代理模型的复杂表示逻辑，ipvs的代理逻辑也较为简单，它仅有两个关键配置要素。首先，kube-proxy会在每个节点上创建一个名为kube-ipvs0的虚拟网络接口，并将集群上所有Service对象的ClusterIP和ExternalIP配置到该接口，使相应IP地址的流量都可被当前节点捕获。其次，kube-proxy会为每个Service生成相关的ipvs虚拟服务器（Virtual Server）定义，该虚拟服务器的真实服务器（Real Server）是由相应Service对象的后端端点组成，到达虚拟服务器VIP（虚拟IP地址）上的服务端口的请求流量由默认或指定的调度算法分发至相关的各真实服务器。<br>但kube-proxy对ClusterIP和NodePort类型Service对象的虚拟服务定义方式略有不同。对于每个ClusterIP类型的Service，kube-proxy仅针对Service_IP生成单个虚拟服务，协议和端口遵循Service的定义。以前面创建的demoapp-svc为例，它的ClusterIP是10.97.72.1，它的虚拟服务定义如下，这些可以通过ipvsadm -Ln命令在集群中的任意一个节点上获取。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node01:~# ipvsadm -Ln | grep -A 3 &quot;10.97.72.1&quot;</span><br><span class="line">TCP  10.97.72.1:80 rr</span><br><span class="line"><span class="meta">  -&gt; </span><span class="language-bash">10.244.1.11:80              Masq    1      0          0</span>         </span><br><span class="line"><span class="meta">  -&gt; </span><span class="language-bash">10.244.2.7:80               Masq    1      0          0</span>         </span><br><span class="line"><span class="meta">  -&gt; </span><span class="language-bash">10.244.3.9:80               Masq    1      0          0</span></span><br></pre></td></tr></table></figure>

<p>而对于NodePort类型Service，kube-proxy会针对kube-ipvs0上的Service_IP:Service_Port，以及当前节点上的所有活动接口的主IP地址的NodePort各定义一个虚拟服务，下面的命令用于获取前面创建的NodePort类型Service对象的demoapp-nodeport-svc的相关虚拟服务的定义。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node01:~# ipvsadm -Ln | grep -E &quot;31398|10.97.56.1&quot;</span><br><span class="line">TCP  172.29.9.11:31398 rr     # 节点IP</span><br><span class="line">TCP  10.97.56.1:80 rr         # ClusterIP</span><br><span class="line">TCP  10.244.1.0:31398 rr      # flannel.1接口IP</span><br><span class="line">TCP  10.244.1.1:31398 rr      # cni0接口IP</span><br><span class="line">TCP  127.0.0.1:31398 rr       # lo接口IP</span><br><span class="line">TCP  172.17.0.1:31398 rr      # docker0接口IP</span><br></pre></td></tr></table></figure>

<p>LoadBalancer类型Service的配置方式与NodePort类型相似，这里不再单独说明。另外，对于每个ExternalI，kube-proxy也会根据每个ExternalIP:Service_Port的组合生成一个虚拟服务，下面的命令及结果显示出前面创建的外部IP地址172.29.9.26相关的虚拟服务。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node01:~# ipvsadm -Ln | grep  &quot;172.29.9.26&quot;</span><br><span class="line">TCP  172.29.9.26:80 rr</span><br></pre></td></tr></table></figure>

<p>上述每种Service类型对应的所有虚拟服务内部同样都使用NAT模式进行请求代理，除了更加多样的调度算法选择外，它的转发性能并没有显著提升，不过因为避免了使用大量的iptables规则，所以系统资源开销显著降低。ipvs仅实现了代理和调度机制，Service资源中的报文过滤和源地址转换等功能，依旧要由iptables完成，但相应的规则数量较少且较为固定。</p>
<h2 id="Kubernetes服务发现"><a href="#Kubernetes服务发现" class="headerlink" title="Kubernetes服务发现"></a>Kubernetes服务发现</h2><p>Kubernetes系统上的Service为Pod中的服务类应用提供了一个固定的访问入口，但Pod客户端中的应用还需要借助服务发现机制获取特定服务的IP和端口。</p>
<h3 id="服务发现概述"><a href="#服务发现概述" class="headerlink" title="服务发现概述"></a>服务发现概述</h3><p>服务发现机制的基本实现，一般是事先部署好一个网络位置较为稳定的服务注册中心（也称为服务总线），由服务提供者（服务端）向注册中心注册自己的位置信息，并在变动后及时予以更新，相应地，服务消费方周期性地从注册中心获取服务提供者的最新位置信息，从而“发现”要访问的目标服务资源。复杂的服务发现机制还会让服务提供者提供其描述信息、状态信息及资源使用信息等，以供消费者实现更为复杂的服务选择逻辑。<br>根据其发现过程的实现方式，服务发现还可分为两种类型：客户端发现和服务端发现。</p>
<ul>
<li>客户端发现：由客户端到服务注册中心发现其依赖的服务的相关信息，因此，它需要内置特定的服务发现程序和发现逻辑。</li>
<li>服务端发现：这种方式额外要用到一个称为中央路由器或服务均衡器的组件；服务消费者将请求发往中央路由器或者负载均衡器，由它们负责查询服务注册中心获取服务提供者的位置信息，并将服务消费者的请求转发给服务提供者。<br>服务注册中心是服务发现得以落地的核心组件。</li>
</ul>
<p>在传统实践中，常见的服务注册中心是ZooKeeper和etcd等分布式键值存储系统，它们可提供基本的数据存储功能，但距离实现完整的服务发现机制还有大量的二次开发任务需要完成。而且，它们更注重数据一致性而不得不弱化可用性（分布式系统的CAP理论），这背离了微服务发现场景中更注重服务可用性的需求。<br>Netflix的Eureka是专用于服务发现的分布式系统，遵从“存在少量的错误数据，总比完全不可用要好”的设计原则，服务发现和可用性是其核心目标，能够在多种故障期间保持服务发现和服务注册的功能。另一个同级别的实现是Consul，它于服务发现的基础功能之外还提供了多数据中心的部署等一众出色的特性。<br>尽管传统的DNS系统不适于微服务环境中的服务发现，但SkyDNS项目结合古老的DNS技术和时髦的Go语言、Raft算法，并构建于etcd存储系统之上，为Kubernetes系统实现了一种独特且实用的服务发现机制。Kubernetes在v1.3版本引入的KubeDNS由kubedns、dnsmasq和sidecar这3个部分组合而成。第一个部分包含kubedns和skydns两个组件，前者负责将Service和Endpoint转换为SkyDNS可以理解的格式；第二部分用于增强解析功能；第三部分为前两者添加健康状态检查机制，因而我们可以把KubeDNS视为SkyDNS的增强版。<br>而另一个基于DNS较新的服务发现项目是由CNCF孵化的CoreDNS，它基于Go语言开发，通过串接一组实现DNS功能的插件的插件链实现所有功能，也允许用户自行开发和添加必要的插件，但所有功能运行在单个容器之中。另外，CoreDNS使用Caddy作为底层的Web Server，可以支持以UDP、TLS、gRPC和HTTPS等方式对外提供DNS服务。自Kubernetes 1.11版本起，CoreDNS取代kubeDNS成为默认的DNS附件。</p>
<h3 id="基于环境变量的服务发现"><a href="#基于环境变量的服务发现" class="headerlink" title="基于环境变量的服务发现"></a>基于环境变量的服务发现</h3><p>创建Pod资源时，kubelet会将其所属名称空间内的每个活动的Service对象以一系列环境变量的形式注入其中。它支持使用Kubernetes Service环境变量以及与Docker的Link兼容的变量。</p>
<h4 id="（1）Kubernetes-Service环境变量"><a href="#（1）Kubernetes-Service环境变量" class="headerlink" title="（1）Kubernetes Service环境变量"></a>（1）Kubernetes Service环境变量</h4><p>Kubernetes为每个Service资源生成包括以下形式的环境变量在内的一系列环境变量，在同一名称空间中创建的Pod对象都会自动拥有这些变量：</p>
<ul>
<li>{SVCNAME}SERVICE_HOST</li>
<li>{SVCNAME}_SERVICE_PORT注意<br>如果SVCNAME中使用了连接线，Kubernetes会在定义环境变量时将其转换为下划线。</li>
</ul>
<h4 id="（2）Docker-Link形式的环境变量"><a href="#（2）Docker-Link形式的环境变量" class="headerlink" title="（2）Docker Link形式的环境变量"></a>（2）Docker Link形式的环境变量</h4><p>Docker使用–link选项实现容器连接时所设置的环境变量形式，具体使用方式请参考Docker的相关文档。在创建Pod对象时，Kubernetes也会把与此形式兼容的一系列环境变量注入Pod对象中。<br>例如，在Service资源demoapp-svc创建后创建的Pod对象中查看可用的环境变量，其中以DEMOAPP_SVC_SERVICE开头的为Kubernetes Service环境变量，名称中不包含SERVICE字符串的环境变量为Docker Link形式的环境变量。下面的命令创建了一个临时Pod对象，并在其命令行列出与demoapp-svc的相关环境变量。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl run client-pod --image=ikubernetes/admin-toolbox:v1.0 -it --<span class="built_in">command</span> -- /bin/sh</span></span><br><span class="line">[root@client-pod /]# printenv | grep DEMOAPP_SVC</span><br><span class="line">DEMOAPP_SVC_SERVICE_PORT_HTTP=80</span><br><span class="line">DEMOAPP_SVC_SERVICE_HOST=10.97.72.1</span><br><span class="line">DEMOAPP_SVC_SERVICE_PORT=80</span><br><span class="line">DEMOAPP_SVC_PORT=tcp://10.97.72.1:80</span><br><span class="line">DEMOAPP_SVC_PORT_80_TCP_ADDR=10.97.72.1</span><br><span class="line">DEMOAPP_SVC_PORT_80_TCP_PORT=80</span><br><span class="line">DEMOAPP_SVC_PORT_80_TCP_PROTO=tcp</span><br><span class="line">DEMOAPP_SVC_PORT_80_TCP=tcp://10.97.72.1:80</span><br></pre></td></tr></table></figure>

<p>基于环境变量的服务发现功能简单、易用，但存在一定局限，例如只有那些与新建Pod对象在同一名称空间中且事先存在的Service对象的信息才会以环境变量形式注入，而那些不在同一名称空间，或者在Pod资源创建之后才创建的Service对象的相关环境变量则不会被添加。</p>
<h3 id="基于DNS的服务发现"><a href="#基于DNS的服务发现" class="headerlink" title="基于DNS的服务发现"></a>基于DNS的服务发现</h3><p>名称解析和服务发现是Kubernetes系统许多功能得以实现的基础服务，ClusterDNS通常是集群安装完成后应该立即部署的附加组件。Kubernetes集群上的每个Service资源对象在创建时都会被自动指派一个遵循&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;格式的名称，并由ClusterDNS为该名称自动生成资源记录，service、ns和zone分别代表服务的名称、名称空间的名称和集群的域名。例如demoapp-svc的DNS名称为demoapp-svc.default.svc.cluster.local.，其中cluster.local.是未明确指定域名后缀的集群默认使用的域名。<br>无论使用kubeDNS还是CoreDNS，它们提供的基于DNS的服务发现解决方案都会负责为该DNS名称解析相应的资源记录类型以实现服务发现。以拥有ClusterIP的多种Service资源类型（ClusterIP、NodePort和LoadBalancer）为例，每个Service对象都会具有以下3个类型的DNS资源记录。</p>
<ul>
<li>1）根据ClusterIP的地址类型，为IPv4生成A记录，为IPv6生成AAAA记录。<ul>
<li>&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;. &lt;ttl&gt; IN A &lt;cluster-ip&gt;</li>
<li>&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;. &lt;ttl&gt; IN AAAA &lt;cluster-ip&gt;</li>
</ul>
</li>
<li>2）为每个定义了名称的端口生成一个SRV记录，未命名的端口号则不具有该记录。<ul>
<li>_&lt;port&gt;._&lt;proto&gt;.&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;.&lt;ttl&gt; IN SRV &lt;weight&gt; &lt;priority&gt; &lt;port-number&gt; &lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;.</li>
</ul>
</li>
<li>3）对于每个给定的A记录（例如a.b.c.d）或AAAA记录（例如a1a2a3a4:b1b2b3b4:c1c2c3c4:d1d2d3d4:e1e2e3e4:f1f2f3f4:g1g2g3g4:h1h2h3h4）都要生成PTR记录，它们各自的格式如下所示：<ul>
<li>&lt;d&gt;.&lt;c&gt;.&lt;b&gt;.&lt;a&gt;.in-addr.arpa. &lt;ttl&gt; IN PTR &lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;.</li>
<li>h4.h3.h2.h1.g4.g3.g2.g1.f4.f3.f2.f1.e4.e3.e2.e1.d4.d3.d2.d1.c4.c3.c2.c1.b4.b3.b2.b1.a4.a3.a2.a1.ip6.arpa &lt;ttl&gt; IN PTR &lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;.<br>例如，</li>
</ul>
</li>
</ul>
<p>前面在default名称空间中创建的Service对象demoapp-svc的地址为10.97.72.1，且为TCP协议的80端口取名http，对于默认的cluster.local域名来说，它会拥有如下3个DNS资源记录。</p>
<ul>
<li>A记录：demoapp-svc.default.svc.cluster.local. 30 IN A 10.97.72.1</li>
<li>SRV记录：_http._tcp.demoapp-svc.default.svc.cluster.local. 30 IN SRV 0 100 80 demoapp- svc.default.svc.cluster.local.</li>
<li>PTR记录：1.72.97.10.in-addr.arpa. 30 IN PTR demoapp-svc.default.svc.cluster.local。</li>
</ul>
<p>kubelet会为创建的每一个容器在/etc/resolv.conf配置文件中生成DNS查询客户端依赖的必要配置，相关的配置信息源自kubelet的配置参数。各容器的DNS服务器由clusterDNS参数的值设定，它的取值为kube-system名称空间中的Service对象kube-dns的ClusterIP，默认为10.96.0.10，而DNS搜索域的值由clusterDomain参数的值设定，若部署Kubernetes集群时未特别指定，其值将为cluster.local、svc.cluster.local和NAMESPACENAME.svc.cluster.local。下面的示例取自集群上一个随机选择的Pod中的容器。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nameserver 10.96.0.10</span><br><span class="line">search default.svc.cluster.local svc.cluster.local cluster.local</span><br><span class="line">options ndots:5</span><br></pre></td></tr></table></figure>

<p>上述search参数中指定的DNS各搜索域，是以次序指定的几个域名后缀，它们各自的域名如下所示。</p>
<ul>
<li>&lt;ns&gt;.svc.&lt;zone&gt;：附带有特定名称空间的域名，例如default.svc.cluster.local。</li>
<li>svc. &lt;zone&gt;：附带了Kubernetes标识Service专用子域svc的域名，例如svc.cluster.local。</li>
<li>&lt;zone&gt;：集群本地域名，例如cluster.local。</li>
</ul>
<p>各容器能够直接向集群上的ClusterDNS发起服务名称和端口名称解析请求完成服务发现，各名称也支持短格式，由搜索域自动补全相关的后缀。我们可以在Kubernetes集群上通过任意一个有nslookup等DNS测试工具的容器进行测试。下面基于此前创建专用于测试的客户端Pod对象client-pod的交互式接口完成后续测试操作。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl <span class="built_in">exec</span> -it client-pod -- /bin/sh</span></span><br><span class="line">[root@client-pod /]#</span><br></pre></td></tr></table></figure>

<p>接下来便可以进行名称解析测试。例如，下面的命令用于请求同一名称空间（default）中的服务名称demoapp-svc的解析结果，并获得了正确的返回值。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@client-pod /]# nslookup -query=A demoapp-svc</span><br><span class="line">Server:         10.96.0.10</span><br><span class="line">Address:        10.96.0.10#53</span><br><span class="line"></span><br><span class="line">Name:   demoapp-svc.default.svc.cluster.local</span><br><span class="line">Address: 10.97.72.1</span><br></pre></td></tr></table></figure>

<p>ClusterDNS解析demoapp-svc服务名称的搜索次序依次是default.svc.cluster.local、svc.cluster.local和cluster.local，因此基于DNS的服务发现不受Service资源所在名称空间和创建时间的限制。上面的解析结果也正是默认的default名称空间中创建的demoapp-svc服务的IP地址。<br>SRV记录中的端口名称的格式_&lt;port&gt;._&lt;proto&gt;.&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;，同样可使用短格式名称。下面的命令用于请求解析demoapp-svc上的http端口，它返回的结果为80。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@client-pod ~]# nslookup -query=SRV _http._tcp.demoapp-svc</span><br><span class="line">Server:         10.96.0.10</span><br><span class="line">Address:        10.96.0.10#53</span><br><span class="line"></span><br><span class="line">_http._tcp.demoapp-svc.default.svc.cluster.local        service = 0 100 80 demoapp-svc.default.svc.cluster.local.</span><br></pre></td></tr></table></figure>

<p>请求解析其他名称空间中的Service对象名称时需要明确指定服务名称和名称空间，下面以kube-dns.kube-system为例进行解析请求。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@client-pod /]# nslookup -query=A kube-dns.kube-system</span><br><span class="line">Server:         10.96.0.10</span><br><span class="line">Address:        10.96.0.10#53</span><br><span class="line"></span><br><span class="line">Name:   kube-dns.kube-system.svc.cluster.local</span><br><span class="line">Address: 10.96.0.10</span><br></pre></td></tr></table></figure>

<p>端口名称解析时同样需要指定Service名称及其所在的名称空间，下面的命令用于请求解析kube-dns.kube-system上的metrics端口，它返回了9153的端口号。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@client-pod /]# nslookup -query=SRV _metrics._tcp.kube-dns.kube-system</span><br><span class="line">Server:         10.96.0.10</span><br><span class="line">Address:        10.96.0.10#53</span><br><span class="line"></span><br><span class="line">_metrics._tcp.kube-dns.kube-system.svc.cluster.local    service = 0 100 9153 kube-dns.kube-system.svc.cluster.local.</span><br></pre></td></tr></table></figure>

<p>为了减少搜索次数，无论是否处于同一名称空间，客户端都可以直接使用FQDN格式的名称解析Service名称和端口名称，这也是在某应用的配置文件中引用其他服务时建议遵循的方式。</p>
<h3 id="Pod的DNS解析策略与配置"><a href="#Pod的DNS解析策略与配置" class="headerlink" title="Pod的DNS解析策略与配置"></a>Pod的DNS解析策略与配置</h3><p>Kubernetes还支持在单个Pod资源规范上自定义DNS解析策略和配置，它们分别使用spec.dnsPolicy和spec.dnsConfig进行定义，并组合生效。目前，Kubernetes支持如下DNS解析策略，它们定义在spec.dnsPolicy字段上。</p>
<ul>
<li>Default：从运行所在的节点继承DNS名称解析相关的配置。</li>
<li>ClusterFirst：在集群DNS服务器上解析集群域内的名称，其他域名的解析则交由从节点继承而来的上游名称服务器。</li>
<li>ClusterFirstWithHostNet：专用于在设置了hostNetwork的Pod对象上使用的ClusterFirst策略，任何配置了hostNetwork的Pod对象都应该显式使用该策略。</li>
<li>None：用于忽略Kubernetes集群的默认设定，而仅使用由dnsConfig自定义的配置。<br>Pod资源的自定义DNS配置要通过嵌套在spec.dnsConfig字段中的如下几个字段进行，它们的最终生效结果要结合dnsPolicy的定义生成。</li>
<li>nameservers &lt;[]string&gt;：DNS名称服务器列表，它附加在由dnsPolicy生成的DNS名称服务器之后。</li>
<li>searches &lt;[]string&gt;：DNS名称解析时的搜索域，它附加在dnsPolicy生成的搜索域之后。</li>
<li>options &lt;[]Object&gt;：DNS解析选项列表，它将会同dnsPolicy生成的解析选项合并成最终生效的定义。<br>下面配置清单示例（pod-with-dnspolicy.yaml）中定义的Pod资源完全使用自定义的配置，它通过将dnsPolicy设置为None而拒绝从节点继承DNS配置信息，并在dnsConfig中自定义了要使用的DNS服务、搜索域和DNS选项。</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-with-dnspolicy</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">demo</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">ikubernetes/demoapp:v1.0</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">  <span class="attr">dnsPolicy:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">dnsConfig:</span></span><br><span class="line">    <span class="attr">nameservers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="number">10.96</span><span class="number">.0</span><span class="number">.10</span></span><br><span class="line">    <span class="bullet">-</span> <span class="number">223.5</span><span class="number">.5</span><span class="number">.5</span></span><br><span class="line">    <span class="bullet">-</span> <span class="number">223.6</span><span class="number">.6</span><span class="number">.6</span></span><br><span class="line">    <span class="attr">searches:</span> </span><br><span class="line">    <span class="bullet">-</span> <span class="string">svc.cluster.local</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">cluster.local</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ilinux.io</span></span><br><span class="line">    <span class="attr">options:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ndots</span></span><br><span class="line">      <span class="attr">value:</span> <span class="string">&quot;5&quot;</span></span><br></pre></td></tr></table></figure>

<p>将上述配置清单中定义的Pod资源创建到集群之上，它最终会生成类似如下内容的/etc/resolv.conf配置文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nameserver 10.96.0.10</span><br><span class="line">nameserver 223.5.5.5</span><br><span class="line">nameserver 223.6.6.6</span><br><span class="line">search svc.cluster.local cluster.local ilinux.io</span><br><span class="line">options ndots:5</span><br></pre></td></tr></table></figure>

<p>上面配置中的搜索域要求，即便是客户端与目标服务位于同一名称空间，也要求在短格式的服务名称上显式指定其所处的名称空间。感兴趣的读者可自行测试其效果。</p>
<h3 id="配置CoreDNS"><a href="#配置CoreDNS" class="headerlink" title="配置CoreDNS"></a>配置CoreDNS</h3><p>CoreDNS是高度模块化的DNS服务器，几乎全部功能均由可插拔的插件实现。CoreDNS调用的插件及相关的配置定义在称为Corefile的配置文件中。CoreDNS主要用于定义各服务器监听地址和端口、授权解析的区域以及加载的插件等，配置格式如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ZONE:[PORT] &#123;</span><br><span class="line">    [PLUGIN]...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>参数说明如下。</p>
<ul>
<li>ZONE：定义该服务器授权解析的区域，它监听由PORT指定的端口。</li>
<li>PLUGIN：定义要加载的插件，每个插件可能存在一系列属性，而每个属性还可能存在可配置的参数。<br>由kubeadm在部署Kubernetes集群时自动部署的CoreDNS的Corefile存储为kube-system名称空间中名为coredns的ConfigMap对象，定义了一个监听53号端口授权解析根区域的服务器，详细的配置信息及各插件的简单说明如下所示。</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">coredns</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">Corefile:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    .:53 &#123;</span></span><br><span class="line"><span class="string">        errors  # 将错误日志发往标准输出stdout</span></span><br><span class="line"><span class="string">        health &#123;  </span></span><br><span class="line"><span class="string">           lameduck 5s</span></span><br><span class="line"><span class="string">        &#125;       # 通过http://localhost:8080/health报告健康状态</span></span><br><span class="line"><span class="string">        ready   # 待所有插件就绪后通过8181端口响应“200 OK”以报告就绪状态</span></span><br><span class="line"><span class="string">        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span></span><br><span class="line"><span class="string">           pods insecure</span></span><br><span class="line"><span class="string">           fallthrough in-addr.arpa ip6.arpa</span></span><br><span class="line"><span class="string">           ttl 30</span></span><br><span class="line"><span class="string">        &#125;       # Kubernetes系统的本地区域及专用的名称解析配置</span></span><br><span class="line"><span class="string">        prometheus :9153  # 通过http://localhost:9153/metrics输出指标数据</span></span><br><span class="line"><span class="string">        forward . /etc/resolv.conf  # 非Kubernetes本地域名的解析转发逻辑</span></span><br><span class="line"><span class="string">        cache 30     # 缓存时长</span></span><br><span class="line"><span class="string">        loop         # 探测转发循环并终止其过程</span></span><br><span class="line"><span class="string">        reload       # Corefile内容改变时自动重载配置信息</span></span><br><span class="line"><span class="string">        loadbalance  # A、AAAA或MX记录的负载均衡器，使用round-robin算法</span></span><br><span class="line"><span class="string">    &#125;</span></span><br></pre></td></tr></table></figure>

<p>在该配置文件中，专用于Kubernetes系统上的名称解析服务由名为kubernetes的插件进行定义，该插件负责处理指定的权威区域中的所有查询，例如上面示例中的正向解析区域cluster.local，以及反向解析区域in-addr.arpa和ip6.arpa。该插件支持多个配置参数，例如endpoint、tls、kubeconfig、namespaces、labels、pods、ttl和fallthrough等，上面示例中用到的3个参数的功能如下。</p>
<ul>
<li>1）pods POD-MODE：设置用于处理基于Pod IP地址的A记录的工作模式，以便在直接同Pod建立SSL通信时验证证书信息；默认值为disabled，表示不处理Pod请求，总是响应NXDOMAIN；在其他可用值中，insecure表示直接响应A记录而无须向Kubernetes进行校验，目标在于兼容kube-dns；而verified表示仅在指定的名称空间中存在一个与A记录中的IP地址相匹配的Pod对象时才会将结果响应给客户端。</li>
<li>2）fallthrough [ZONES…]：常规情况下，该插件的权威区域解析结果为NXDOMAIN时即为最终结果，而该参数允许将该响应的请求继续转给后续的其他插件处理；省略指定目标区域时表示生效于所有区域，否则，将仅生效于指定的区域。</li>
<li>3）ttl：自定义响应结果的可缓存时长，默认为5秒，可用值范围为[0,3600]。<br>那些非由kubernetes插件所负责解析的本地匹配的名称，将由forward插件定义的方式转发给其他DNS服务器进行解析，示例中的配置表示将根区域的解析请求转发给主机配置文件/etc/resolv.conf中指定的DNS服务器进行。若要将请求直接转发给指定的DNS服务器，则将该文件路径替换为目标DNS服务器的IP地址即可，多个IP地址之间以空白字符分隔。例如，下面的配置示例表示将除了ilinux.io区域之外的其他请求转给223.5.5.5或223.6.6.6进行解析。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">. &#123;</span><br><span class="line">  forward . 223.5.5.5 223.6.6.6 &#123;</span><br><span class="line">    except ilinux.io</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>CoreDNS的各插件与相关的配置属性、参数及详细使用方式请参考官方文档中的介绍：<a target="_blank" rel="noopener" href="https://coredns.io/plugins/%E3%80%82">https://coredns.io/plugins/。</a></p>
<h2 id="Headless-Service资源解析"><a href="#Headless-Service资源解析" class="headerlink" title="Headless Service资源解析"></a>Headless Service资源解析</h2><p>常规的ClusterIP、NodePort和LoadBalancer类型的Service对象可通过不同的入口来接收和分发客户端请求，且它们都拥有集群IP地址（ClusterIP）。然而，个别场景也可能不必或无须使用Service对象的负载均衡功能以及集群IP地址，而是借助ClusterDNS服务来代替实现这部分功能。Kubernetes把这类不具有ClusterIP的Service资源形象地称为Headless Service，该Service的请求流量无须kube-proxy处理，也不会有负载均衡和路由相关的iptables或ipvs规则。至于ClusterDNS如何自动配置Headless Service，则取决于Service标签选择器的定义。</p>
<ul>
<li>有标签选择器：由端点控制器自动创建与Service同名的Endpoint资源，而ClusterDNS则将Service名称的A记录直接解析为后端各端点的IP而非ClusterIP。</li>
<li>无标签选择器：ClusterDNS的配置分为两种情形，为ExternalName类型的服务（配置了spec.externalName字段）创建CNAME记录，而为与该Service同名的Endpoint对象上的每个端点创建一个A记录。<br>显然，ClusterDNS对待无标签选择器的第二种情形的Headless Service与对待有标签选择器的Headless </li>
</ul>
<p>Service的方式相同，区别仅在于相应的Endpoint资源是否由端点控制器基于标签选择器自动创建。通常，我们把无标签选择器的第一种情形（使用CNAME记录）的Headless Service当作一种独立的Service类型使用，即ExternalName Service，而将那些把Service名称使用A记录解析为端点IP地址的类型统一称为Headless Service。</p>
<h3 id="ExternalName-Service"><a href="#ExternalName-Service" class="headerlink" title="ExternalName Service"></a>ExternalName Service</h3><p>ExternalName Service是一种特殊类型的Service资源，它不需要使用标签选择器关联任何Pod对象，也无须定义任何端口或Endpoints，但必须要使用spec.externalName属性定义一个CNAME记录，用于返回真正提供服务的服务名称的别名。ClusterDNS会为这种类型的Service资源自动生成&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;. &lt;ttl&gt; IN CNAME &lt;extname&gt;.格式的DNS资源记录。<br>下面配置清单示例（externalname-redis-svc.yaml）中定义了一个名为externalname-redis-svc的Service资源，它使用DNS CNAME记录指向集群外部的redis.ik8s.io这一FQDN。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">externalname-redis-svc</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ExternalName</span></span><br><span class="line">  <span class="attr">externalName:</span> <span class="string">redis.ik8s.io</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">6379</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">6379</span></span><br><span class="line">    <span class="attr">nodePort:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">selector:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>待Service资源externalname-redis-svc创建完成后，各Pod对象即可通过短格式或FQDN格式的Service名称访问相应的服务。ClusterDNS会把该名称以CNAME格式解析为.spec.externalName字段中的名称，而后通过DNS服务将其解析为相应主机的IP地址。我们可通过此前Pod对象client-pod对该名称进行解析测试。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl <span class="built_in">exec</span> -it client -- /bin/sh</span>                                            </span><br><span class="line">[root@client-pod /]#</span><br></pre></td></tr></table></figure>

<p>未指定解析类型的，nslookup命令会对解析得到的CNAME结果自动进行更进一步的解析。例如下面命令中，请求解析externalname-redis-svc.default.svc.cluster.local名称得到CNAME格式的结果redis.ik8s.io将被进一步解析为A记录格式的结果。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@client-pod /]# nslookup externalname-redis-svc</span><br><span class="line">Server:         10.96.0.10</span><br><span class="line">Address:        10.96.0.10#53</span><br><span class="line"></span><br><span class="line">externalname-redis-svc.default.svc.cluster.local    canonical name = redis.ik8s.io.</span><br><span class="line">Name:   redis.ik8s.io</span><br><span class="line">Address: 1.2.3.4</span><br></pre></td></tr></table></figure>

<p>ExternalName用于通过DNS别名将外部服务发布到Kubernetes集群上，这类的DNS别名同本地服务的DNS名称具有相同的形式。因而Pod对象可像发现和访问集群内部服务一样来访问这些发布到集群之上的外部服务，这样隐藏了服务的位置信息，使得各工作负载能够以相同的方式调用本地和外部服务。等到了能够或者需要把该外部服务引入到Kubernetes集群上之时，管理员只需要修改相应ExternalName Service对象的类型为集群本地服务即可。</p>
<h3 id="Headless-Service"><a href="#Headless-Service" class="headerlink" title="Headless Service"></a>Headless Service</h3><p>除了为每个Service资源对象在创建时自动指派一个遵循&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;格式的DNS名称，ClusterDNS还会为Headless Service中的每个端点指派一个遵循&lt;hostname&gt;. &lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;格式的DNS名称，因此，每个Headless Service资源对象的名称都会由ClusterDNS自动生成以下几种类型的资源记录。</p>
<ul>
<li>1）根据端点IP地址的类型，在Service名称上为每个IPv4地址的端点生成A记录，为IPv6地址的端点生成AAAA记录。<ul>
<li>&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;. &lt;ttl&gt; IN A &lt;endpoint-ip&gt;</li>
<li>&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;. &lt;ttl&gt; IN AAAA &lt;endpoint-ip&gt;</li>
</ul>
</li>
<li>2）根据端点IP地址的类型，在端点自身的hostname名称上为每个IPv4地址的端点生成A记录，为IPv6地址的端点生成AAAA记录。<ul>
<li>&lt;hostname&gt;.&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;. &lt;ttl&gt; IN A &lt;endpoint-ip&gt;</li>
<li>&lt;hostname&gt;.&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;. &lt;ttl&gt; IN AAAA &lt;endpoint-ip&gt;</li>
</ul>
</li>
<li>3）为每个定义了名称的端口生成一个SRV记录，未命名的端口号则不具有该记录。</li>
<li>_&lt;port&gt;._&lt;proto&gt;.&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;. &lt;ttl&gt; IN SRV &lt;weight&gt; &lt;priority&gt; &lt;port-number&gt; &lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;.</li>
<li>4）对于每个给定的每个端点的主机名称的A记录（例如a.b.c.d）或AAAA记录（例如a1a2a3a4:b1b2b3b4:c1c2c3c4:d1d2d3d4:e1e2e3e4:f1f2f3f4:g1g2g3g4:h1h2h3h4），都要生成PTR记录，它们各自的格式如下所示。<ul>
<li>&lt;d&gt;.&lt;c&gt;.&lt;b&gt;.&lt;a&gt;.in-addr.arpa. &lt;ttl&gt; IN PTR &lt;hostname&gt;.&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;.</li>
<li>h4.h3.h2.h1.g4.g3.g2.g1.f4.f3.f2.f1.e4.e3.e2.e1.d4.d3.d2.d1.c4.c3.c2.c1.b4.b3.b2.b1.a4.a3.a2.a1.ip6.arpa &lt;ttl&gt; IN PTR &lt;hostname&gt;.&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;.<br>定义Service资源时，只需要将其ClusterIP字段的值显式设置为None即可将其定义为Headless类型。下面是一个Headless Service资源配置示例，它拥有标签选择器，因而能够自动创建同名的Endpoint资源。</li>
</ul>
</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">demoapp-headless-svc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">demoapp</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">http</span></span><br></pre></td></tr></table></figure>

<p>将上面定义的Headless Service资源创建到集群上，我们从其资源详细描述中可以看出，demoapp-headless-svc没有ClusterIP，但因标签选择器能够匹配到Pod资源，因此它拥有端点记录。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl apply -f demoapp-headless-svc.yaml</span> </span><br><span class="line">service/demoapp-headless-svc created</span><br><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl describe svc demoapp-headless-svc</span></span><br><span class="line">Name:              demoapp-headless-svc</span><br><span class="line">Namespace:         default</span><br><span class="line">Labels:            &lt;none&gt;</span><br><span class="line">Annotations:       Selector:  app=demoapp</span><br><span class="line">Type:              ClusterIP</span><br><span class="line">IP:                None</span><br><span class="line">Port:              http  80/TCP</span><br><span class="line">TargetPort:        80/TCP</span><br><span class="line">Endpoints:         10.244.1.16:80,10.244.2.10:80,10.244.3.11:80</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

<p>根据Headless Service的工作特性可知，它记录在ClusterDNS的A记录的相关解析结果是后端端点的IP地址，这就意味着客户端通过此Service资源的名称发现的是各Pod资源。下面依然通过Pod对象client-pod的交互式接口进行测试：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$ </span><span class="language-bash">kubectl <span class="built_in">exec</span> -it client-pod -- /bin/sh</span></span><br><span class="line">[root@client-pod /]# nslookup -query=A demoapp-headless-svc</span><br><span class="line">Server:         10.96.0.10</span><br><span class="line">Address:        10.96.0.10#53</span><br><span class="line"></span><br><span class="line">Name:   demoapp-headless-svc.default.svc.cluster.local</span><br><span class="line">Address: 10.244.3.11</span><br><span class="line">Name:   demoapp-headless-svc.default.svc.cluster.local</span><br><span class="line">Address: 10.244.1.16</span><br><span class="line">Name:   demoapp-headless-svc.default.svc.cluster.local</span><br><span class="line">Address: 10.244.2.10</span><br></pre></td></tr></table></figure>

<p>其解析结果正是Headless Service通过标签选择器关联到的所有Pod资源的IP地址。于是，客户端向此Service对象发起的请求将直接接入Pod资源中的应用之上，而不再由Service资源进行代理转发，它每次接入的Pod资源是由DNS服务器接收到查询请求时以轮询方式返回的IP地址。<br>另一方面，每个IP地址的反向解析记录（PTR）对应的FQDN名称是相应端点所在主机的主机名称。对于Kubernetes上的容器来说，其所在主机的主机名是指Pod对象上的主机名称，它由Pod资源的spec.hostname字段和spec.subdomain组合定义，格式为&lt;hostname&gt;.subdomain&gt;.&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;，其中的&lt;subdomain&gt;可省略。若此两者都未定义，则&lt;hostname&gt;值取自IP地址，IP地址a.b.c.d对应的主机名为a-b-c-d，如下面命令的解析结果所示。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@client-pod /]# nslookup -query=PTR 10.244.3.11</span><br><span class="line">Server:         10.96.0.10</span><br><span class="line">Address:        10.96.0.10#53</span><br><span class="line">11.3.244.10.in-addr.arpa        name = 10-244-3-11.demoapp-headless-svc.default.svc.cluster.local.</span><br></pre></td></tr></table></figure>

<p>StatefulSet控制器对象是Headless Service资源的一个典型应用场景，相关话题将会在第8章中详细描</p>
<h2 id="本章小结"><a href="#本章小结" class="headerlink" title="本章小结"></a>本章小结</h2><p>本章重点讲解了Kubernetes的Service资源基础概念、类型、实现机制及其发布方式等话题，并介绍了服务发现及Headless Service。</p>
<ul>
<li>Service资源通过标签选择器为一组任务负载创建一个统一的访问入口，它把客户端请求代理调度至后端各端点。</li>
<li>Service支持userspace、iptables和ipvs代理模型，iptables模式更为成熟稳定，而ipvs则在有大规模Service的场景中有着更好的性能表现。</li>
<li>ClusterIP是最基础的Service类型，它仅适用于集群内通信，NodePort和LoadBalancer能够将服务发布到集群外部；外部IP能够与这3种类型的Service组合使用，从而开放特定的IP接入外部流量。</li>
<li>Endpoint和EndpointSlice用于跟踪端点资源，并将端点信息提供给Service等。</li>
<li>Headless Service是没有ClusterIP的Service资源类型，它要么结合externalName以CNAME资源记录的形式映射至其他服务，要么以A记录或AAAA记录的形式解析至端点IP地址。</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/blog/tags/Kubernetes/" rel="tag"># Kubernetes</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/blog/2022/02/09/Kubernetes%E5%9F%BA%E7%A1%80/" rel="prev" title="Kubernetes基础">
      <i class="fa fa-chevron-left"></i> Kubernetes基础
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A0%87%E7%AD%BE%E4%B8%8E%E6%A0%87%E7%AD%BE%E9%80%89%E6%8B%A9%E5%99%A8"><span class="nav-number">1.</span> <span class="nav-text">标签与标签选择器</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B5%84%E6%BA%90%E6%A0%87%E7%AD%BE"><span class="nav-number">1.1.</span> <span class="nav-text">资源标签</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E8%B5%84%E6%BA%90%E6%97%B6%E5%AE%9A%E4%B9%89%E6%A0%87%E7%AD%BE"><span class="nav-number">1.1.1.</span> <span class="nav-text">创建资源时定义标签</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A0%87%E7%AD%BE%E9%80%89%E6%8B%A9%E5%99%A8"><span class="nav-number">1.2.</span> <span class="nav-text">标签选择器</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Service%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0"><span class="nav-number">2.</span> <span class="nav-text">Service与服务发现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Service%E8%B5%84%E6%BA%90%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.1.</span> <span class="nav-text">Service资源及其实现模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Service%E8%B5%84%E6%BA%90%E6%A6%82%E8%BF%B0"><span class="nav-number">2.1.1.</span> <span class="nav-text">Service资源概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-proxy%E4%BB%A3%E7%90%86%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.1.2.</span> <span class="nav-text">kube-proxy代理模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#userspace%E4%BB%A3%E7%90%86%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.1.2.1.</span> <span class="nav-text">userspace代理模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#iptables%E4%BB%A3%E7%90%86%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.1.2.2.</span> <span class="nav-text">iptables代理模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ipvs%E4%BB%A3%E7%90%86%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.1.2.3.</span> <span class="nav-text">ipvs代理模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Service%E8%B5%84%E6%BA%90%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.1.3.</span> <span class="nav-text">Service资源类型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%881%EF%BC%89ClusterIP"><span class="nav-number">2.1.3.1.</span> <span class="nav-text">（1）ClusterIP</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%882%EF%BC%89NodePort"><span class="nav-number">2.1.3.2.</span> <span class="nav-text">（2）NodePort</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%883%EF%BC%89LoadBalancer"><span class="nav-number">2.1.3.3.</span> <span class="nav-text">（3）LoadBalancer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%884%EF%BC%89ExternalName"><span class="nav-number">2.1.3.4.</span> <span class="nav-text">（4）ExternalName</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BA%94%E7%94%A8Service%E8%B5%84%E6%BA%90"><span class="nav-number">2.2.</span> <span class="nav-text">应用Service资源</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BA%94%E7%94%A8ClusterIP-Service%E8%B5%84%E6%BA%90"><span class="nav-number">2.2.1.</span> <span class="nav-text">应用ClusterIP Service资源</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BA%94%E7%94%A8NodePort-Service%E8%B5%84%E6%BA%90"><span class="nav-number">2.2.2.</span> <span class="nav-text">应用NodePort Service资源</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BA%94%E7%94%A8LoadBalancer-Service%E8%B5%84%E6%BA%90"><span class="nav-number">2.2.3.</span> <span class="nav-text">应用LoadBalancer Service资源</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%96%E9%83%A8IP"><span class="nav-number">2.2.4.</span> <span class="nav-text">外部IP</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Service%E4%B8%8EEndpoint%E8%B5%84%E6%BA%90"><span class="nav-number">2.3.</span> <span class="nav-text">Service与Endpoint资源</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Endpoint%E4%B8%8E%E5%AE%B9%E5%99%A8%E6%8E%A2%E9%92%88"><span class="nav-number">2.3.1.</span> <span class="nav-text">Endpoint与容器探针</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89Endpoint%E8%B5%84%E6%BA%90"><span class="nav-number">2.3.2.</span> <span class="nav-text">自定义Endpoint资源</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Service%E8%B5%84%E6%BA%90"><span class="nav-number">2.4.</span> <span class="nav-text">深入理解Service资源</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#iptables%E4%BB%A3%E7%90%86%E6%A8%A1%E5%9E%8B-1"><span class="nav-number">2.4.1.</span> <span class="nav-text">iptables代理模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ClusterIP-Service"><span class="nav-number">2.4.1.1.</span> <span class="nav-text">ClusterIP Service</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ipvs%E4%BB%A3%E7%90%86%E6%A8%A1%E5%9E%8B-1"><span class="nav-number">2.4.2.</span> <span class="nav-text">ipvs代理模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kubernetes%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0"><span class="nav-number">2.5.</span> <span class="nav-text">Kubernetes服务发现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%E6%A6%82%E8%BF%B0"><span class="nav-number">2.5.1.</span> <span class="nav-text">服务发现概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0"><span class="nav-number">2.5.2.</span> <span class="nav-text">基于环境变量的服务发现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%881%EF%BC%89Kubernetes-Service%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="nav-number">2.5.2.1.</span> <span class="nav-text">（1）Kubernetes Service环境变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%882%EF%BC%89Docker-Link%E5%BD%A2%E5%BC%8F%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="nav-number">2.5.2.2.</span> <span class="nav-text">（2）Docker Link形式的环境变量</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8EDNS%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0"><span class="nav-number">2.5.3.</span> <span class="nav-text">基于DNS的服务发现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pod%E7%9A%84DNS%E8%A7%A3%E6%9E%90%E7%AD%96%E7%95%A5%E4%B8%8E%E9%85%8D%E7%BD%AE"><span class="nav-number">2.5.4.</span> <span class="nav-text">Pod的DNS解析策略与配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AECoreDNS"><span class="nav-number">2.5.5.</span> <span class="nav-text">配置CoreDNS</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Headless-Service%E8%B5%84%E6%BA%90%E8%A7%A3%E6%9E%90"><span class="nav-number">2.6.</span> <span class="nav-text">Headless Service资源解析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ExternalName-Service"><span class="nav-number">2.6.1.</span> <span class="nav-text">ExternalName Service</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Headless-Service"><span class="nav-number">2.6.2.</span> <span class="nav-text">Headless Service</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%AC%E7%AB%A0%E5%B0%8F%E7%BB%93"><span class="nav-number">2.7.</span> <span class="nav-text">本章小结</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description">myBlog</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">4</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/muse.js"></script>


<script src="/blog/js/next-boot.js"></script>




  















  

  

</body>
</html>
